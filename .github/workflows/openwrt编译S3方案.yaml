name: å…¨æ–°ç¼–è¯‘ç¬¬12ç‰ˆ(Gemini-S3Cache)

on:
  workflow_dispatch:
    inputs:
      ssh:
        description: 'SSHè°ƒè¯•'
        required: false
        default: 'false'
      clean_build:
        description: 'å…¨æ–°ç¼–è¯‘ï¼Œä¸ä½¿ç”¨ä»»ä½•æ¢å¤çš„ç¼“å­˜ (åŒ…æ‹¬S3å’ŒActions Cache)ã€‚ä»ä¼šå°è¯•ä¿å­˜æ–°ç¼“å­˜åˆ°S3å’ŒActions Cacheã€‚'
        required: false
        default: 'false' 
      config_file:
        description: 'é…ç½®æ–‡ä»¶ (ä½äºä»“åº“æ ¹ç›®å½•)'
        required: false
        default: 'å¢é‡ç¼“å­˜ä¼˜åŒ–.config'

env:
  REPO_URL: https://github.com/coolsnowwolf/lede
  REPO_BRANCH: master 
  FEEDS_CONF_URL: https://github.com/tikkacn/openwrt-new-rom/raw/main/feeds.conf.default
  CONFIG_FILE_NAME: ${{ github.event.inputs.config_file || 'å¢é‡ç¼“å­˜ä¼˜åŒ–.config' }}
  DIY_P1_SH_NAME: diy-part1.sh 
  DIY_P2_SH_NAME: diy-part2.sh 
  UPLOAD_FIRMWARE: true
  UPLOAD_RELEASE: true
  TZ: Asia/Shanghai

  # GitHub Actions Caches Paths
  CCACHE_DIR_PATH: /workdir/ccache 
  PACKAGES_BIN_DIR_PATH: /workdir/openwrt/bin 
  BUILD_STATE_DIR_PATH: /workdir/build_state 

  # S3 ç¼“å­˜çš„ç›®æ ‡ç›®å½•çš„ç»å¯¹è·¯å¾„
  S3_TARGET_STAGING_DIR_PATH: /workdir/openwrt/staging_dir
  S3_TARGET_HOST_BUILD_DIR_PATH: /workdir/openwrt/build_dir/host
  S3_TARGET_TOOLCHAIN_BUILD_DIR_PATH: /workdir/openwrt/build_dir/toolchain-x86_64_gcc-13.3.0_musl 
  S3_TARGET_DL_DIR_PATH: /workdir/openwrt/dl

  # S3 ç¼“å­˜å‹ç¼©åŒ…çš„æœ¬åœ°æ–‡ä»¶å
  S3_STAGING_DIR_ARCHIVE_FILENAME: staging_dir_cache.tar.zst
  S3_HOST_BUILD_DIR_ARCHIVE_FILENAME: host_build_dir_cache.tar.zst
  S3_TOOLCHAIN_BUILD_DIR_ARCHIVE_FILENAME: toolchain_build_dir_cache.tar.zst
  S3_DL_DIR_ARCHIVE_FILENAME: dl_dir_cache.tar.zst
  
  # S3_PATH_PREFIX_KEY å°†åœ¨ä¸‹é¢çš„æ­¥éª¤ä¸­åŠ¨æ€è®¾ç½®
  S3_CONFIG_SNAPSHOT_FILENAME: latest_successful_build.config 

  CCACHE_LOGFILE_PATH: /tmp/ccache_detailed.log
  DEBUG_LOG_FILE_PATH: /tmp/build_debug_summary.log

jobs:
  build:
    runs-on: ubuntu-22.04

    steps:
    - name: æ£€å‡ºä»£ç  (Checkout)
      uses: actions/checkout@main

    - name: è®¾ç½® S3 ç¼“å­˜è·¯å¾„å‰ç¼€ (Set S3 Cache Path Prefix)
      run: |
        s3_prefix_from_secret="${{ secrets.S3_CACHE_PATH_PREFIX }}"
        if [ -n "$s3_prefix_from_secret" ]; then
          echo "S3_PATH_PREFIX_KEY=$s3_prefix_from_secret" >> $GITHUB_ENV
          echo "ä½¿ç”¨æ¥è‡ª Secret 'S3_CACHE_PATH_PREFIX' çš„S3è·¯å¾„å‰ç¼€: $s3_prefix_from_secret" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        else
          default_prefix="openwrt-caches/${{ env.REPO_BRANCH }}"
          echo "S3_PATH_PREFIX_KEY=$default_prefix" >> $GITHUB_ENV
          echo "ä½¿ç”¨é»˜è®¤S3è·¯å¾„å‰ç¼€: $default_prefix" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        fi

    - name: ä¼˜åŒ–ç£ç›˜ç©ºé—´ (Maximize Build Space)
      uses: easimon/maximize-build-space@master
      with:
        root-reserve-mb: 20480 
        swap-size-mb: 5120
        remove-dotnet: 'true'
        remove-android: 'true'
        remove-haskell: 'true'
        remove-codeql: 'true'
        remove-docker-images: 'true'
        build-mount-path: '/workdir'

    - name: é¢å¤–æ¸…ç†ç£ç›˜ç©ºé—´å¹¶æ£€æŸ¥ (Extra Cleanup & Check)
      run: |
        echo "æ¸…ç†é¢å¤–ç£ç›˜ç©ºé—´..."
        sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /usr/local/share/boost /usr/share/swift /usr/local/julia* /opt/hostedtoolcache/CodeQL
        docker image prune -a -f || true
        docker system prune -af || true
        sudo apt-get clean && sudo apt-get autoremove -y
        df -h

    - name: åˆå§‹åŒ–ç¯å¢ƒå’Œå®‰è£… AWS CLI (Initialize Environment & Install AWS CLI)
      env:
        DEBIAN_FRONTEND: noninteractive
      run: |
        sudo -E apt-get -qq update
        sudo -E apt-get -qq install ack antlr3 asciidoc autoconf automake autopoint binutils bison build-essential \
        bzip2 ccache clang cmake cpio curl device-tree-compiler flex gawk gcc-multilib g++-multilib gettext \
        genisoimage git gperf haveged help2man intltool libc6-dev-i386 libelf-dev libfuse-dev libglib2.0-dev \
        libgmp3-dev libltdl-dev libmpc-dev libmpfr-dev libncurses5-dev libncursesw5-dev libpython3-dev \
        libreadline-dev libssl-dev libtool llvm lrzsz msmtp ninja-build p7zip p7zip-full patch pkgconf \
        python3 python3-pyelftools python3-setuptools qemu-utils rsync scons squashfs-tools subversion \
        swig texinfo uglifyjs upx-ucl unzip vim wget xmlto xxd zlib1g-dev \
        awscli 
        sudo -E apt-get -qq clean
        sudo timedatectl set-timezone "$TZ"
        mkdir -p ${{ env.BUILD_STATE_DIR_PATH }} ${{ env.CCACHE_DIR_PATH }} /workdir/openwrt 
        chmod -R 777 /workdir
        
        CONFIG_FILE_ON_RUNNER="${GITHUB_WORKSPACE}/${{ env.CONFIG_FILE_NAME }}"
        DIY_P1_SH_ON_RUNNER="${GITHUB_WORKSPACE}/${{ env.DIY_P1_SH_NAME }}"
        DIY_P2_SH_ON_RUNNER="${GITHUB_WORKSPACE}/${{ env.DIY_P2_SH_NAME }}"

        echo '#!/bin/bash' > "${DIY_P1_SH_ON_RUNNER}"
        echo "echo '[INFO] Running default diy-part1.sh. FEEDS_CONF_URL is: ${{ env.FEEDS_CONF_URL }}'" >> "${DIY_P1_SH_ON_RUNNER}"
        chmod +x "${DIY_P1_SH_ON_RUNNER}"

        echo '#!/bin/bash' > "${DIY_P2_SH_ON_RUNNER}"
        echo 'BANNER_DATE=$(date +"%Y%m%d%H%M")' >> "${DIY_P2_SH_ON_RUNNER}"
        echo 'sed -i "s/OpenWrt /OpenWrt_S3Build_${BANNER_DATE} /" package/lean/default-settings/files/zzz-default-settings' >> "${DIY_P2_SH_ON_RUNNER}"
        echo "echo '[INFO] Running default diy-part2.sh (Banner updated).'" >> "${DIY_P2_SH_ON_RUNNER}"
        chmod +x "${DIY_P2_SH_ON_RUNNER}"
        
        if [ ! -f "${CONFIG_FILE_ON_RUNNER}" ]; then
          echo "è­¦å‘Šï¼šé…ç½®æ–‡ä»¶ ${CONFIG_FILE_ON_RUNNER} ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"
          echo "# Default minimal .config created by workflow" > "${CONFIG_FILE_ON_RUNNER}"
          echo "CONFIG_TARGET_x86=y" >> "${CONFIG_FILE_ON_RUNNER}"
          echo "CONFIG_TARGET_x86_64=y" >> "${CONFIG_FILE_ON_RUNNER}"
          echo "CONFIG_TARGET_x86_64_DEVICE_generic=y" >> "${CONFIG_FILE_ON_RUNNER}"
          echo "CONFIG_PACKAGE_luci=y" >> "${CONFIG_FILE_ON_RUNNER}"
        fi
        df -h
        echo "AWS CLI version: $(aws --version)"

    - name: é…ç½® AWS å‡­è¯ (Configure AWS Credentials)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: å…‹éš†æºä»£ç å¹¶åˆ›å»ºåŸºç¡€ç›®å½•ç»“æ„ (Clone Source & Setup Dirs)
      working-directory: /workdir 
      run: |
        echo "æ­£åœ¨æ¸…ç†å¯èƒ½å·²å­˜åœ¨çš„ /workdir/openwrt ç›®å½•..."
        rm -rf /workdir/openwrt
        echo "å…‹éš†æ–°çš„æºä»£ç åˆ° /workdir/openwrt..."
        git clone --depth 1 ${{ env.REPO_URL }} -b ${{ env.REPO_BRANCH }} openwrt
        ln -sf /workdir/openwrt ${{ env.GITHUB_WORKSPACE }}/openwrt 
        cd openwrt 
        mkdir -p ${{ env.S3_TARGET_STAGING_DIR_PATH }} ${{ env.S3_TARGET_HOST_BUILD_DIR_PATH }} ${{ env.S3_TARGET_TOOLCHAIN_BUILD_DIR_PATH }} \
                   ${{ env.S3_TARGET_DL_DIR_PATH }} \
                   ${{ env.PACKAGES_BIN_DIR_PATH }} ${{ env.BUILD_STATE_DIR_PATH }} ${{ env.CCACHE_DIR_PATH }}
        mkdir -p logs 
        echo "åŸºç¡€ç›®å½•ç»“æ„åˆ›å»º/ç¡®è®¤å®Œæ¯•ã€‚"

    # --- GitHub Actions Cache Restore (Small Caches) ---
    - name: æ¢å¤ç¼–è¯‘äº§ç‰©ç¼“å­˜ (bin/ ç›®å½•)
      uses: actions/cache@v3
      id: cache-packages-bin
      if: inputs.clean_build != 'true'
      with:
        path: ${{ env.PACKAGES_BIN_DIR_PATH }} 
        key: packages-bin-${{ env.REPO_BRANCH }}-${{ hashFiles(format('{0}/{1}', env.GITHUB_WORKSPACE, env.CONFIG_FILE_NAME)) }}-v1 

    - name: æ¢å¤CCACHEç¼“å­˜
      uses: actions/cache@v3
      id: cache-ccache
      with: 
        path: ${{ env.CCACHE_DIR_PATH }}
        key: ccache-${{ env.REPO_BRANCH }}-${{ hashFiles(format('{0}/{1}', env.GITHUB_WORKSPACE, env.CONFIG_FILE_NAME)) }}-v1

    - name: æ¢å¤æ„å»ºçŠ¶æ€ç¼“å­˜
      uses: actions/cache@v3
      id: cache-state
      if: inputs.clean_build != 'true'
      with:
        path: ${{ env.BUILD_STATE_DIR_PATH }}
        key: state-${{ env.REPO_BRANCH }}-${{ hashFiles(format('{0}/{1}', env.GITHUB_WORKSPACE, env.CONFIG_FILE_NAME)) }}-v1
    # --- END GitHub Actions Cache Restore ---

    # --- S3 Cache Restore (Large Caches) ---
    - name: ä» S3 æ¢å¤å¤§ä½“ç§¯ç¼“å­˜ (Download & Extract S3 Caches)
      if: inputs.clean_build != 'true'
      working-directory: /workdir/openwrt 
      run: |
        S3_BUCKET_NAME="${{ secrets.AWS_S3_BUCKET_NAME }}"
        S3_FULL_PREFIX="${{ env.S3_PATH_PREFIX_KEY }}" # This is now set by the 'Set S3 Cache Path Prefix' step
        OPENWRT_ROOT_DIR=$(pwd) 

        if [ -z "$S3_BUCKET_NAME" ]; then
          echo "[ERROR] AWS_S3_BUCKET_NAME secret æœªè®¾ç½®ã€‚è·³è¿‡S3ç¼“å­˜æ¢å¤ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          exit 0 
        fi
        echo "[INFO] S3 Bucket: $S3_BUCKET_NAME, S3 Cache Prefix: $S3_FULL_PREFIX" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

        s3_download_and_untar() {
          local s3_archive_filename="$1"    
          local target_abs_dir_path="$2"    
          local s3_object_key="${S3_FULL_PREFIX}/${s3_archive_filename}"
          local local_archive_on_runner="./${s3_archive_filename}" 

          echo "å°è¯•ä» S3 ä¸‹è½½: s3://${S3_BUCKET_NAME}/${s3_object_key} åˆ° ${local_archive_on_runner} ..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          if aws s3 cp "s3://${S3_BUCKET_NAME}/${s3_object_key}" "${local_archive_on_runner}" --quiet; then
            echo "ä¸‹è½½ ${s3_archive_filename} æˆåŠŸ. å¼€å§‹è§£å‹..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            if [ -d "${target_abs_dir_path}" ]; then
              echo "åˆ é™¤å·²å­˜åœ¨çš„ç›®å½•: ${target_abs_dir_path}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
              rm -rf "${target_abs_dir_path}"
            fi
            if tar -I "zstd -T0" -xf "${local_archive_on_runner}" -C "${OPENWRT_ROOT_DIR}"; then 
              echo "è§£å‹ ${s3_archive_filename} (å†…å®¹åˆ° $(basename ${target_abs_dir_path})) æˆåŠŸã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            else
              echo "é”™è¯¯ï¼šè§£å‹ ${s3_archive_filename} å¤±è´¥ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
              rm -rf "${target_abs_dir_path}" 
            fi
            rm -f "${local_archive_on_runner}" 
          else
            echo "ä» S3 ä¸‹è½½ ${s3_archive_filename} (s3://${S3_BUCKET_NAME}/${s3_object_key}) å¤±è´¥æˆ–æ–‡ä»¶ä¸å­˜åœ¨ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          fi
        }

        s3_download_and_untar "${{ env.S3_STAGING_DIR_ARCHIVE_FILENAME }}" "${{ env.S3_TARGET_STAGING_DIR_PATH }}"
        s3_download_and_untar "${{ env.S3_HOST_BUILD_DIR_ARCHIVE_FILENAME }}" "${{ env.S3_TARGET_HOST_BUILD_DIR_PATH }}"
        s3_download_and_untar "${{ env.S3_TOOLCHAIN_BUILD_DIR_ARCHIVE_FILENAME }}" "${{ env.S3_TARGET_TOOLCHAIN_BUILD_DIR_PATH }}"
        s3_download_and_untar "${{ env.S3_DL_DIR_ARCHIVE_FILENAME }}" "${{ env.S3_TARGET_DL_DIR_PATH }}"
        
        df -h | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
    # --- END S3 Cache Restore ---

    - name: æ£€æŸ¥ç¼“å­˜æ¢å¤åçŠ¶æ€ (Check Cache Restore Status)
      run: |
        echo "--- Debug Log: Cache Restore Status Summary ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "CONFIG_FILE: ${{ env.CONFIG_FILE_NAME }}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "GitHub Packages Bin Cache: ${{ steps.cache-packages-bin.outputs.cache-hit == 'true' && 'Hit' || 'Miss/Skipped' }}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "GitHub CCACHE Cache: ${{ steps.cache-ccache.outputs.cache-hit == 'true' && 'Hit' || 'Miss' }}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "GitHub Build State Cache: ${{ steps.cache-state.outputs.cache-hit == 'true' && 'Hit' || 'Miss/Skipped' }}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "--- Debug Log: Directory Sizes After All Restores ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        du -sh ${{ env.S3_TARGET_STAGING_DIR_PATH }} 2>/dev/null || echo "Staging Dir (${{ env.S3_TARGET_STAGING_DIR_PATH }}) ä¸å­˜åœ¨æˆ–ä¸ºç©º" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        du -sh ${{ env.S3_TARGET_HOST_BUILD_DIR_PATH }} 2>/dev/null || echo "Host Build Dir (${{ env.S3_TARGET_HOST_BUILD_DIR_PATH }}) ä¸å­˜åœ¨æˆ–ä¸ºç©º" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        du -sh ${{ env.S3_TARGET_TOOLCHAIN_BUILD_DIR_PATH }} 2>/dev/null || echo "Toolchain Build Dir (${{ env.S3_TARGET_TOOLCHAIN_BUILD_DIR_PATH }}) ä¸å­˜åœ¨æˆ–ä¸ºç©º" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        du -sh ${{ env.S3_TARGET_DL_DIR_PATH }} 2>/dev/null || echo "DL Dir (${{ env.S3_TARGET_DL_DIR_PATH }}) ä¸å­˜åœ¨æˆ–ä¸ºç©º" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        du -sh ${{ env.PACKAGES_BIN_DIR_PATH }} 2>/dev/null || echo "Packages Bin Dir (${{ env.PACKAGES_BIN_DIR_PATH }}) ä¸å­˜åœ¨æˆ–ä¸ºç©º" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        du -sh ${{ env.CCACHE_DIR_PATH }} 2>/dev/null || echo "CCACHE Dir (${{ env.CCACHE_DIR_PATH }}) ä¸å­˜åœ¨æˆ–ä¸ºç©º" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        df -h | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "--- End Debug Log ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

    - name: é…ç½®ç¼–è¯‘ç¯å¢ƒ (Configure Build Environment)
      run: |
        cd /workdir/openwrt
        CONFIG_FILE_ON_RUNNER="${GITHUB_WORKSPACE}/${{ env.CONFIG_FILE_NAME }}"
        DIY_P1_SH_ON_RUNNER="${GITHUB_WORKSPACE}/${{ env.DIY_P1_SH_NAME }}"
        DIY_P2_SH_ON_RUNNER="${GITHUB_WORKSPACE}/${{ env.DIY_P2_SH_NAME }}"

        # If .config exists (e.g. from S3 cache of a full build_dir or if a previous step created it)
        # and we are not doing a clean build, we might prefer it.
        # However, current logic copies the repo's config file over any restored .config.
        if [ -f ".config" ] && [ "${{ inputs.clean_build }}" != "true" ]; then 
          echo "æ£€æµ‹åˆ°å·²å­˜åœ¨çš„ .config (å¯èƒ½æ¥è‡ªS3ç¼“å­˜æ¢å¤), è¾“å…¥çš„é…ç½®æ–‡ä»¶å°†è¦†ç›–å®ƒã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        fi

        $DIY_P1_SH_ON_RUNNER
        echo "æ›´æ–°å¹¶å®‰è£… Feeds..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        ./scripts/feeds update -a
        ./scripts/feeds install -a
        if [ -e "${GITHUB_WORKSPACE}/files" ]; then
          echo "å¤åˆ¶è‡ªå®šä¹‰æ–‡ä»¶ files/ ..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          cp -r "${GITHUB_WORKSPACE}/files" ./
        fi
        echo "ä½¿ç”¨é…ç½®æ–‡ä»¶: ${CONFIG_FILE_ON_RUNNER}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        cp "${CONFIG_FILE_ON_RUNNER}" ./.config
        cp .config .config.input 
        $DIY_P2_SH_ON_RUNNER
        
        echo "CONFIG_AUTOREMOVE=y" >> .config 
        echo "CONFIG_AUTOREBUILD=y" >> .config 
        echo "ç¡®ä¿å¿…è¦çš„å›ºä»¶ç”Ÿæˆé€‰é¡¹..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        if ! grep -q "CONFIG_TARGET_ROOTFS_SQUASHFS=y" .config; then echo "CONFIG_TARGET_ROOTFS_SQUASHFS=y" >> .config; fi
        if ! grep -q "CONFIG_TARGET_IMAGES_GZIP=y" .config; then echo "CONFIG_TARGET_IMAGES_GZIP=y" >> .config; fi
        if ! grep -q "CONFIG_TARGET_ROOTFS_TARGZ=y" .config; then echo "CONFIG_TARGET_ROOTFS_TARGZ=y" >> .config; fi
        if grep -q "CONFIG_TARGET_x86=y" .config; then
          if ! grep -q "CONFIG_GRUB_IMAGES=y" .config; then echo "CONFIG_GRUB_IMAGES=y" >> .config; fi
          if ! grep -q "CONFIG_TARGET_IMAGES_PAD=y" .config; then echo "CONFIG_TARGET_IMAGES_PAD=y" >> .config; fi
        fi
        
        echo "æ‰§è¡Œ make defconfig..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        make defconfig
        
        grep "^CONFIG_PACKAGE_.*=y" .config.input | sort > packages_input.txt || true
        grep "^CONFIG_PACKAGE_.*=y" .config | sort > packages_defconfig.txt || true
        comm -23 packages_input.txt packages_defconfig.txt > missing_packages.txt
        if [ -s missing_packages.txt ]; then
          echo "è­¦å‘Šï¼šä»¥ä¸‹åŒ…åœ¨ defconfig åç¼ºå¤±ï¼Œå°†å°è¯•æ¢å¤ï¼š" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          cat missing_packages.txt | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          cat missing_packages.txt >> .config 
          echo "é‡æ–°æ‰§è¡Œ make defconfig ä»¥ç¡®ä¿ä¾èµ–ä¸€è‡´æ€§ (å› æœ‰åŒ…è¢«é‡æ–°åŠ å…¥)" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          make defconfig
        else
          echo "æ‰€æœ‰åœ¨è¾“å…¥ .config ä¸­æŒ‡å®šçš„ CONFIG_PACKAGE_*=y é…ç½®é¡¹åœ¨ defconfig åå‡ä¿ç•™æˆ–è¢«æ­£ç¡®å¤„ç†ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        fi
        diff -u .config.input .config > config_diff.txt || echo "é…ç½®æ–‡ä»¶ (.config.input vs .config) æ— å·®å¼‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "Config diff å·²ä¿å­˜åˆ° config_diff.txt" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        df -h | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

    - name: æ£€æŸ¥æºç å˜åŒ– (Feeds Makefile Hashes)
      id: check-feeds
      run: |
        cd /workdir/openwrt
        mkdir -p ${{ env.BUILD_STATE_DIR_PATH }}
        find feeds -type f -name "Makefile" -exec sha256sum {} \; | sort | sha256sum > ${{ env.BUILD_STATE_DIR_PATH }}/feeds.sha256
        CURRENT_FEEDS_HASH=$(cat ${{ env.BUILD_STATE_DIR_PATH }}/feeds.sha256 | awk '{print $1}')
        PREVIOUS_FEEDS_HASH=$(cat ${{ env.BUILD_STATE_DIR_PATH }}/previous_feeds.sha256 2>/dev/null | awk '{print $1}' || echo "")
        echo "--- Debug Log: Feeds Change Check ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "å½“å‰ feeds å“ˆå¸Œ: $CURRENT_FEEDS_HASH" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "ä¹‹å‰ feeds å“ˆå¸Œ: $PREVIOUS_FEEDS_HASH" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        if [ "$CURRENT_FEEDS_HASH" != "$PREVIOUS_FEEDS_HASH" ]; then
          echo "feeds_changed=true" >> $GITHUB_ENV
          echo "Feeds çš„ Makefile ç»“æ„å·²å˜æ›´ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        else
          echo "feeds_changed=false" >> $GITHUB_ENV
          echo "Feeds çš„ Makefile ç»“æ„æœªå˜æ›´ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        fi
        echo "--- End Debug Log: Feeds Change Check ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        cp ${{ env.BUILD_STATE_DIR_PATH }}/feeds.sha256 ${{ env.BUILD_STATE_DIR_PATH }}/previous_feeds.sha256

    - name: å¼€å¯SSHè°ƒè¯• (å¦‚æœéœ€è¦) (Enable SSH if needed)
      uses: mxschmitt/action-tmate@v3
      if: github.event.inputs.ssh == 'true'

    - name: ä¸‹è½½è½¯ä»¶åŒ… (make download)
      run: |
        cd /workdir/openwrt
        MAX_RETRIES=3
        RETRY_WAIT=10
        cat > download_with_retry.sh << 'EOF'
        #!/bin/bash
        set -e; MAX_RETRIES=$1; RETRY_WAIT=$2; shift 2; retries=0
        until [ $retries -ge $MAX_RETRIES ]; do
          echo "å°è¯•ä¸‹è½½ï¼Œç¬¬ $((retries+1)) æ¬¡ï¼Œå…± $MAX_RETRIES æ¬¡...";
          mkdir -p logs 
          if make download -j$(nproc) "$@" 2>&1 | tee "logs/download_attempt_$(date +%s)_$retries.log"; then echo "ä¸‹è½½æˆåŠŸï¼"; exit 0; fi
          retries=$((retries+1));
          if [ $retries -lt $MAX_RETRIES ]; then echo "ä¸‹è½½å¤±è´¥ï¼Œç­‰å¾… $RETRY_WAIT ç§’åé‡è¯•..."; sleep $RETRY_WAIT; fi
        done
        echo "è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¿å­˜æ—¥å¿—ä»¥åˆ†æå¤±è´¥çš„åŒ…...";
        LAST_LOG=$(ls -t logs/download_attempt_*.log 2>/dev/null | head -n 1)
        if [ -n "$LAST_LOG" ]; then cp "$LAST_LOG" logs/download_failures.log; else echo "æ— æ³•æ‰¾åˆ°ä¸‹è½½å°è¯•æ—¥å¿—ã€‚" > logs/download_failures.log; fi
        exit 1
        EOF
        chmod +x download_with_retry.sh
        if ! ./download_with_retry.sh $MAX_RETRIES $RETRY_WAIT; then
            echo "ä¸‹è½½é‡è¯•å¤±è´¥ï¼Œå°è¯•å•çº¿ç¨‹è¯¦ç»†æ—¥å¿—ä¸‹è½½..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            make download -j1 V=s 2>&1 | tee logs/download_final_attempt.log || true 
        fi
        mkdir -p ${{ env.CCACHE_DIR_PATH }}
        ccache -o cache_dir=${{ env.CCACHE_DIR_PATH }}
        ccache -o max_size=8G 
        ccache -z 
        echo "CCACHE é…ç½®å®Œæˆå¹¶å·²æ¸…é›¶ç»Ÿè®¡æ•°æ®ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        df -h
        
    - name: æ£€æµ‹å¹¶å¤„ç†ä¸‹è½½å¤±è´¥çš„åŒ… (Detect & Handle Failed Downloads)
      run: |
        cd /workdir/openwrt
        if [ -f "logs/download_failures.log" ] || [ -f "logs/download_final_attempt.log" ]; then
            COMBINED_DOWNLOAD_LOG="logs/combined_download_errors.log"
            cat logs/download_failures.log logs/download_final_attempt.log 2>/dev/null > "$COMBINED_DOWNLOAD_LOG"
            echo "åˆ†æä¸‹è½½å¤±è´¥æ—¥å¿— ($COMBINED_DOWNLOAD_LOG)..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }};
            grep -E "(curl:.*(Couldn't resolve host|Connection timed out|403 Forbidden|404 Not Found)|No more mirrors to try|Download failed)" "$COMBINED_DOWNLOAD_LOG" > failed_urls.txt || true;
            declare -A failed_packages_map;
            while IFS= read -r line; do
                if [[ $line =~ \/([^\/_]+([_-][0-9a-zA-Z\.]+)?)\.(tar\.|zip|gz|xz|bz2) ]]; then
                    pkg_name_from_url="${BASH_REMATCH[1]}"
                    pkg_name_from_url_base=$(echo "$pkg_name_from_url" | sed -E 's/[-_][0-9]+.*//; s/-git//')
                    if [ -n "$pkg_name_from_url_base" ]; then failed_packages_map["$pkg_name_from_url_base"]=1; echo "æ£€æµ‹åˆ°å¯èƒ½ä¸‹è½½å¤±è´¥çš„åŒ… (åŸºäºURL): $pkg_name_from_url_base" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}; fi
                fi
            done < failed_urls.txt;
            if [ ${#failed_packages_map[@]} -gt 0 ]; then
                echo "ä»¥ä¸‹åŒ…æˆ–å…¶æºç å¯èƒ½ä¸‹è½½å¤±è´¥ï¼Œå°†å°è¯•ä» .config ä¸­ç¦ç”¨ï¼š" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }};
                PACKAGES_MODIFIED=0
                for pkg_base in "${!failed_packages_map[@]}"; do
                    echo " - ç–‘ä¼¼é—®é¢˜åŒ…: $pkg_base" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }};
                    if grep -q "CONFIG_PACKAGE_.*${pkg_base}.*=y" .config; then
                        echo "  åœ¨ .config ä¸­æ‰¾åˆ°ç›¸å…³åŒ…ï¼Œå°è¯•ç¦ç”¨..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                        sed -i -E "/CONFIG_PACKAGE_.*${pkg_base}.*=y/s/=y$/=n # Auto-disabled due to download failure/g" .config
                        PACKAGES_MODIFIED=1
                    fi
                done;
                if [ $PACKAGES_MODIFIED -eq 1 ]; then echo "ç”±äºæ£€æµ‹åˆ°ä¸‹è½½å¤±è´¥ï¼Œå·²ä¿®æ”¹ .config æ–‡ä»¶ï¼Œé‡æ–°è¿è¡Œ make defconfig" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}; make defconfig;
                else echo "æœªåœ¨ .config ä¸­æ‰¾åˆ°æ˜ç¡®åŒ¹é…çš„å·²å¯ç”¨åŒ…è¿›è¡Œç¦ç”¨ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}; fi
            else echo "æœªä»ä¸‹è½½æ—¥å¿—ä¸­æ˜ç¡®è¯†åˆ«å‡ºç‰¹å®šä¸‹è½½å¤±è´¥çš„åŒ…åã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}; fi
        else echo "æ²¡æœ‰æ‰¾åˆ°ä¸‹è½½å¤±è´¥çš„æ—¥å¿—æ–‡ä»¶ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}; fi
        echo "ä¸‹è½½å¤±è´¥åŒ…æ£€æµ‹å¤„ç†å®Œæˆã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

    - name: æ™ºèƒ½ç¼–è¯‘å›ºä»¶ (Smart Compile Firmware)
      id: compile
      run: |
        echo "--- Debug Log: Compile Step Start ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        cd /workdir/openwrt
        export CCACHE_DIR=${{ env.CCACHE_DIR_PATH }}
        export PATH="/usr/lib/ccache:$PATH" 
        export CCACHE_LOGFILE=${{ env.CCACHE_LOGFILE_PATH }}
        echo "CCACHE_LOGFILE in compile step set to: $CCACHE_LOGFILE_PATH" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

        cleanup_temp_files() { 
          echo "æ¸…ç†ä¸´æ—¶æ–‡ä»¶ä»¥é‡Šæ”¾ç©ºé—´..."; find /tmp -maxdepth 1 -type f -delete || true; df -h | tee -a ${{ env.DEBUG_LOG_FILE_PATH }};
        }

        save_md5_info_to_build_state() { 
          echo "ä¿å­˜é…ç½®MD5ä¿¡æ¯åˆ°æ„å»ºçŠ¶æ€ç›®å½•..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          mkdir -p ${{ env.BUILD_STATE_DIR_PATH }};
          cp .config ${{ env.BUILD_STATE_DIR_PATH }}/config_from_compile_step.txt; 
          echo "$TOOLCHAIN_MD5" > ${{ env.BUILD_STATE_DIR_PATH }}/toolchain.md5;
          echo "$PACKAGE_MD5" > ${{ env.BUILD_STATE_DIR_PATH }}/package.md5;
          echo "æ„å»ºçŠ¶æ€MD5ä¿¡æ¯ä¿å­˜å®Œæˆã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        }
        
        handle_make_error_robust() { 
          local make_log_content="$1"
          local make_command_failed="$2"
          echo "ç¼–è¯‘å‘½ä»¤ '$make_command_failed' å¤±è´¥ã€‚æ—¥å¿—å¦‚ä¸‹ï¼š" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          echo "$make_log_content" >> ${{ env.DEBUG_LOG_FILE_PATH }} # Append to main debug log
          if echo "$make_log_content" | grep -q -E "(No more mirrors to try|Download failed|Couldn't resolve host|404 Not Found|403 Forbidden)"; then
            echo "é”™è¯¯ä¼¼ä¹ä¸ä¸‹è½½ç›¸å…³ï¼Œä½†ä¸‹è½½æ­¥éª¤åº”å·²å¤„ç†ã€‚è¯·æ£€æŸ¥åŒ…çš„Makefileã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          fi
          return 1 
        }

        compile_firmware() {
          echo ">>> CCACHE: Zeroing statistics for this compile_firmware run." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          ccache -z
          echo ">>> CCACHE: Statistics at START of compile_firmware (after zeroing):" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          ccache -s | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

          MAKE_JOBS=$(nproc)
          MAIN_MAKE_CMD="make -j${MAKE_JOBS} V=s"
          FALLBACK_MAKE_CMD="make -j1 V=s" 
          
          # Use a timestamped log file for each compile_firmware invocation's main output
          COMPILE_OUTPUT_LOG="logs/compile_output_$(date +%Y%m%d_%H%M%S).log"
          echo "è¯¦ç»†ç¼–è¯‘æ—¥å¿—å°†è¾“å‡ºåˆ°: ${COMPILE_OUTPUT_LOG}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          
          if [ $DO_FULL_BUILD -eq 1 ]; then
            echo "--- Compile Branch: Full Build ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            echo "éœ€è¦å®Œæ•´æ„å»ºã€‚å°†ç¼–è¯‘ä¸»æœºå·¥å…·ã€å·¥å…·é“¾ï¼ˆå¦‚æœS3ç¼“å­˜æ— æ•ˆæˆ–ç¼ºå¤±ï¼‰ï¼Œç„¶åæ˜¯æ•´ä¸ªworldã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            make tools/compile $FALLBACK_MAKE_CMD || make tools/compile $FALLBACK_MAKE_CMD 
            make toolchain/compile $FALLBACK_MAKE_CMD || make toolchain/compile $FALLBACK_MAKE_CMD 
            cleanup_temp_files
            echo "å¼€å§‹å®Œæ•´ç¼–è¯‘ (World)..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            if ! $MAIN_MAKE_CMD 2>&1 | tee "${COMPILE_OUTPUT_LOG}"; then
              if ! handle_make_error_robust "$(cat ${COMPILE_OUTPUT_LOG})" "$MAIN_MAKE_CMD"; then 
                 echo "å®Œæ•´ç¼–è¯‘é¦–æ¬¡å°è¯•å¤±è´¥ï¼Œå°è¯•å•çº¿ç¨‹ç¼–è¯‘..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                 $FALLBACK_MAKE_CMD 2>&1 | tee -a "${COMPILE_OUTPUT_LOG}" 
              fi
            fi
          elif [ $DO_PACKAGE_BUILD -eq 1 ] || [ "${{ env.feeds_changed }}" = "true" ]; then
            echo "--- Compile Branch: Package Build or Feeds Changed ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            echo "è½¯ä»¶åŒ…é…ç½®æˆ–Feedsç»“æ„å·²å˜æ›´ï¼Œå°†æ‰§è¡Œ package/clean, package/compile, package/index." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            make package/clean V=s || true 
            if ! make package/compile $MAIN_MAKE_CMD 2>&1 | tee "${COMPILE_OUTPUT_LOG}"; then
               if ! handle_make_error_robust "$(cat ${COMPILE_OUTPUT_LOG})" "package/compile $MAIN_MAKE_CMD"; then
                 echo "è½¯ä»¶åŒ…ç¼–è¯‘é¦–æ¬¡å°è¯•å¤±è´¥ï¼Œå°è¯•å•çº¿ç¨‹ç¼–è¯‘..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                 make package/compile $FALLBACK_MAKE_CMD 2>&1 | tee -a "${COMPILE_OUTPUT_LOG}"
               fi
            fi
            make package/index V=s || make package/index $FALLBACK_MAKE_CMD 
          else
            echo "--- Compile Branch: Minimal Incremental Build ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            echo "é…ç½®å’ŒFeedså‡æœªæ˜¾è‘—å˜åŒ–ï¼Œæ‰§è¡Œæœ€å°åŒ–å¢é‡ç¼–è¯‘ (World)..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            if ! $MAIN_MAKE_CMD 2>&1 | tee "${COMPILE_OUTPUT_LOG}"; then
              if ! handle_make_error_robust "$(cat ${COMPILE_OUTPUT_LOG})" "$MAIN_MAKE_CMD"; then
                 echo "æœ€å°åŒ–å¢é‡ç¼–è¯‘é¦–æ¬¡å°è¯•å¤±è´¥ï¼Œå°è¯•å•çº¿ç¨‹ç¼–è¯‘..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                 $FALLBACK_MAKE_CMD 2>&1 | tee -a "${COMPILE_OUTPUT_LOG}"
              fi
            fi
          fi
          
          echo "æ‰€æœ‰ç¼–è¯‘åˆ†æ”¯æ‰§è¡Œå®Œæ¯•ï¼Œç¡®ä¿æ‰§è¡Œæœ€ç»ˆçš„å›ºä»¶ç”Ÿæˆæ­¥éª¤ (target/install)..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          make target/install $FALLBACK_MAKE_CMD 2>&1 | tee -a "${COMPILE_OUTPUT_LOG}" # Append to the same log
          local final_install_status=$? 
          
          save_md5_info_to_build_state 

          echo "æ£€æŸ¥å›ºä»¶ç”Ÿæˆç»“æœ (make target/install status: $final_install_status):" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          find bin/targets -type f \( -name "*.bin" -o -name "*combined*" -o -name "*sysupgrade*" -o -name "*.img.gz" \) -print0 | xargs -0 ls -lh || echo "æ²¡æœ‰æ‰¾åˆ°ä¸»è¦å›ºä»¶æ–‡ä»¶ï¼" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          
          echo ">>> CCACHE: Statistics at END of compile_firmware function:" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          ccache -s | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

          if [ ${final_install_status} -eq 0 ] && [ -n "$(find bin/targets -type f \( -name "*.bin" -o -name "*combined*" -o -name "*sysupgrade*" -o -name "*.img.gz" \) -print -quit)" ]; then
            echo "compile_firmwareå‡½æ•°åˆ¤æ–­ä¸ºæˆåŠŸ (å›ºä»¶å·²ç”Ÿæˆ)ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            return 0 
          else
            echo "compile_firmwareå‡½æ•°åˆ¤æ–­ä¸ºå¤±è´¥ (å›ºä»¶æœªç”Ÿæˆæˆ–target/installå‡ºé”™)ã€‚æœ€ç»ˆç¼–è¯‘æ—¥å¿—åœ¨ ${COMPILE_OUTPUT_LOG}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            return 1 
          fi
        }
        
        TOOLCHAIN_CONFIG_SUBSET_FOR_MD5=$(grep -E "^CONFIG_TARGET|^CONFIG_ARCH|^CONFIG_TOOLCHAIN" .config | grep -v "NOT_SET" | sort)
        TOOLCHAIN_MD5=$(echo "$TOOLCHAIN_CONFIG_SUBSET_FOR_MD5" | md5sum | awk '{print $1}')
        PREVIOUS_TOOLCHAIN_MD5=$(cat ${{ env.BUILD_STATE_DIR_PATH }}/toolchain.md5 2>/dev/null || echo "not_found_in_state_cache")
        PACKAGE_CONFIG_SUBSET_FOR_MD5=$(grep "^CONFIG_PACKAGE_" .config | grep "=y" | sort) 
        PACKAGE_MD5=$(echo "$PACKAGE_CONFIG_SUBSET_FOR_MD5" | md5sum | awk '{print $1}')
        PREVIOUS_PACKAGE_MD5=$(cat ${{ env.BUILD_STATE_DIR_PATH }}/package.md5 2>/dev/null || echo "not_found_in_state_cache")
        DO_FULL_BUILD=0
        DO_PACKAGE_BUILD=0

        echo "--- Debug Log: Build Decision Variables (based on final .config) ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "Input clean_build: ${{ github.event.inputs.clean_build }}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "Current TOOLCHAIN_MD5: $TOOLCHAIN_MD5" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "Previous TOOLCHAIN_MD5 (from BUILD_STATE_DIR cache): $PREVIOUS_TOOLCHAIN_MD5" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "Current PACKAGE_MD5: $PACKAGE_MD5" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "Previous PACKAGE_MD5 (from BUILD_STATE_DIR cache): $PREVIOUS_PACKAGE_MD5" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "env.feeds_changed: ${{ env.feeds_changed }}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

        if [ "${{ github.event.inputs.clean_build }}" = "true" ]; then
          echo "clean_build is true: DO_FULL_BUILD=1 (å…¨æ–°ç¼–è¯‘ï¼Œä¸ä½¿ç”¨å·²æ¢å¤çš„ç¼“å­˜)" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          DO_FULL_BUILD=1
        # Check S3 cache status (using GITHUB_OUTPUT from S3 restore step is more robust, but direct check is an alternative)
        # For simplicity, we assume if S3 restore step ran (clean_build=false) and key dirs are not well populated, it's a full build.
        # This logic can be refined if `s3_download_and_untar` sets an output.
        elif [ ! -f "${{ env.S3_TARGET_STAGING_DIR_PATH }}/stamp/.prepared" ] || \
             [ ! -d "${{ env.S3_TARGET_HOST_BUILD_DIR_PATH }}/stamp" ] || \
             [ ! -d "${{ env.S3_TARGET_TOOLCHAIN_BUILD_DIR_PATH }}/stamp" ]; then
          echo "ä¸€ä¸ªæˆ–å¤šä¸ªå…³é”®S3ç¼“å­˜ç›®å½•ä¼¼ä¹ä¸å®Œæ•´æˆ–æœªæ¢å¤ï¼Œæ‰§è¡Œå®Œæ•´æ„å»ºé€»è¾‘: DO_FULL_BUILD=1" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          DO_FULL_BUILD=1
        elif [ "$PREVIOUS_TOOLCHAIN_MD5" = "not_found_in_state_cache" ] || [ "$TOOLCHAIN_MD5" != "$PREVIOUS_TOOLCHAIN_MD5" ]; then
          echo "Toolchain config MD5 å˜åŒ–æˆ–é¦–æ¬¡æ„å»º (åŸºäºstateç¼“å­˜)ï¼Œæ‰§è¡Œå®Œæ•´æ„å»ºé€»è¾‘: DO_FULL_BUILD=1" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          DO_FULL_BUILD=1
        elif [ "$PREVIOUS_PACKAGE_MD5" = "not_found_in_state_cache" ] || [ "$PACKAGE_MD5" != "$PREVIOUS_PACKAGE_MD5" ]; then
          echo "Package config MD5 å˜åŒ– (åŸºäºstateç¼“å­˜)ï¼Œæ‰§è¡ŒåŒ…ç¼–è¯‘é€»è¾‘: DO_PACKAGE_BUILD=1" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          DO_PACKAGE_BUILD=1
        elif [ "${{ env.feeds_changed }}" = "true" ]; then
           echo "Feeds ç»“æ„å·²å˜æ›´ (é…ç½®MD5æœªå˜)ï¼Œæ‰§è¡ŒåŒ…ç¼–è¯‘é€»è¾‘: DO_PACKAGE_BUILD=1" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
           DO_PACKAGE_BUILD=1
        else
           echo "æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œç¼“å­˜åº”æœ‰æ•ˆï¼Œæ‰§è¡Œæœ€å°åŒ–å¢é‡æ„å»ºã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        fi
        
        echo "Final Build Strategy -> DO_FULL_BUILD: $DO_FULL_BUILD, DO_PACKAGE_BUILD: $DO_PACKAGE_BUILD" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "--- End Debug Log: Build Decision Variables ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

        if compile_firmware; then
          echo "DEVICE_NAME=_$(grep '^CONFIG_TARGET.*DEVICE.*=y' .config | sed -r 's/.*DEVICE_(.*)=y/\1/' | tr '\n' '_' | sed 's/_$//')" >> $GITHUB_ENV
          echo "FILE_DATE=_$(date +"%Y%m%d%H%M")" >> $GITHUB_ENV
          echo "status=success" >> $GITHUB_OUTPUT
        else
          echo "status=failure" >> $GITHUB_OUTPUT
        fi
        
        echo "Final ccache stats for this entire 'æ™ºèƒ½ç¼–è¯‘å›ºä»¶' step run:" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        ccache -s | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        df -h | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "--- Debug Log: Compile Step End ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

    - name: æ£€æŸ¥ç¼–è¯‘åå„ç›®å½•å¤§å° (S3ç¼“å­˜ä¸Šä¼ å‰) (Check Sizes Before S3 Upload)
      if: "!cancelled()" 
      run: |
        echo "ç¼–è¯‘å®Œæˆæˆ–ä¸­æ­¢ï¼Œè¯¦ç»†æ£€æŸ¥å„æ„å»ºç›®å½•å¤§å°..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        CURRENT_DATE_WITH_TZ=$(date +"%Y-%m-%d %H:%M:%S %Z")
        echo "" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "--- è¯¦ç»†ç›®å½•å¤§å°æ£€æŸ¥ (du -sh) ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "æ£€æŸ¥æ—¶é—´: $CURRENT_DATE_WITH_TZ" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "--------------------------------------------------" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        
        check_and_log_size() {
            local dir_path="$1"
            local dir_desc="$2"
            local readable_size="æœªçŸ¥æˆ–ç›®å½•ä¸å­˜åœ¨"
            if [ -e "${dir_path}" ]; then 
                readable_size=$(du -sh "${dir_path}" 2>/dev/null | awk '{print $1}')
                if [ -z "${readable_size}" ]; then readable_size="è·å–å¤±è´¥æˆ–ä¸ºç©º"; fi
                echo "$dir_desc (${dir_path}): ${readable_size}" 
                echo "[SIZE_CHECK] $dir_desc (${dir_path}): ${readable_size}" >> ${{ env.DEBUG_LOG_FILE_PATH }}
            else
                echo "$dir_desc (${dir_path}): ç›®å½•ä¸å­˜åœ¨" 
                echo "[SIZE_CHECK] $dir_desc (${dir_path}): ç›®å½•ä¸å­˜åœ¨" >> ${{ env.DEBUG_LOG_FILE_PATH }}
            fi
        }

        check_and_log_size "${{ env.S3_TARGET_STAGING_DIR_PATH }}" "1. Staging Dir (è®¡åˆ’S3ç¼“å­˜)"
        check_and_log_size "${{ env.S3_TARGET_TOOLCHAIN_BUILD_DIR_PATH }}" "2. Toolchain Build Dir (è®¡åˆ’S3ç¼“å­˜)"
        check_and_log_size "${{ env.S3_TARGET_HOST_BUILD_DIR_PATH }}" "3. Host Build Dir (è®¡åˆ’S3ç¼“å­˜)"
        check_and_log_size "${{ env.S3_TARGET_DL_DIR_PATH }}" "4. DL Dir (è®¡åˆ’S3ç¼“å­˜)"
        check_and_log_size "${{ env.PACKAGES_BIN_DIR_PATH }}" "5. ç¼–è¯‘äº§ç‰©è¾“å‡ºç›®å½• (bin/, Actions Cache)" 
        check_and_log_size "${{ env.CCACHE_DIR_PATH }}" "6. CCACHEç›®å½• (Actions Cache)"
        check_and_log_size "/workdir/openwrt/build_dir/" "7. æ•´ä¸ª OpenWrt build_dir ç›®å½• (å‚è€ƒ)"
        check_and_log_size "${{ env.BUILD_STATE_DIR_PATH }}" "8. æ„å»ºçŠ¶æ€ç›®å½• (Actions Cache)"
        
        echo "--------------------------------------------------" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "--- è¯¦ç»†ç›®å½•å¤§å°æ£€æŸ¥ç»“æŸ ---" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        echo "" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

        mkdir -p ${{ env.BUILD_STATE_DIR_PATH }} 
        echo "æ„å»ºçŠ¶æ€æ—¶é—´æˆ³: $CURRENT_DATE_WITH_TZ" > ${{ env.BUILD_STATE_DIR_PATH }}/build_run_timestamp.txt
        echo "è¿è¡ŒID: ${{ github.run_id }}" >> ${{ env.BUILD_STATE_DIR_PATH }}/build_run_timestamp.txt
        echo "æ„å»ºåˆ†æ”¯: ${{ env.REPO_BRANCH }}" >> ${{ env.BUILD_STATE_DIR_PATH }}/build_run_timestamp.txt
        echo "[DEBUG_LOG] å·²æ›´æ–°æ„å»ºè¿è¡Œæ—¶é—´æˆ³æ–‡ä»¶: ${{ env.BUILD_STATE_DIR_PATH }}/build_run_timestamp.txt" >> ${{ env.DEBUG_LOG_FILE_PATH }}

    # --- S3 Cache Save (Large Caches) ---
    - name: æ‰“åŒ…å¹¶ä¸Šä¼ å¤§ä½“ç§¯ç¼“å­˜åˆ° S3 (Pack & Upload Large Caches to S3)
      if: steps.compile.outputs.status == 'success' && !cancelled() 
      working-directory: /workdir/openwrt 
      run: |
        S3_BUCKET_NAME="${{ secrets.AWS_S3_BUCKET_NAME }}"
        S3_FULL_PREFIX="${{ env.S3_PATH_PREFIX_KEY }}" # Use the env var set by the early step
        CONFIG_FILE_TO_UPLOAD=".config" # Path relative to /workdir/openwrt

        if [ -z "$S3_BUCKET_NAME" ]; then
          echo "[ERROR] AWS_S3_BUCKET_NAME secret æœªè®¾ç½®ã€‚æ— æ³•ä¸Šä¼ ç¼“å­˜åˆ°S3ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          exit 1 
        fi
        echo "[INFO] S3 Bucket for Upload: $S3_BUCKET_NAME, S3 Cache Prefix: $S3_FULL_PREFIX" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

        s3_pack_and_upload() {
          local source_dir_relative_to_pwd="$1" # e.g., staging_dir (relative to /workdir/openwrt)
          local s3_archive_filename="$2"        # e.g., staging_dir_cache.tar.zst
          local s3_object_key="${S3_FULL_PREFIX}/${s3_archive_filename}"
          local local_archive_in_pwd="./${s3_archive_filename}" # Temp archive in /workdir/openwrt

          if [ ! -d "$source_dir_relative_to_pwd" ]; then
            echo "ç›®å½• $source_dir_relative_to_pwd ä¸å­˜åœ¨äº $(pwd)ï¼Œè·³è¿‡æ‰“åŒ…å’Œä¸Šä¼ ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            return
          fi
          
          echo "å¼€å§‹æ‰“åŒ…å‹ç¼©ç›®å½•: $source_dir_relative_to_pwd ä¸º $local_archive_in_pwd ..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          # Using current dir as context for tar
          if tar -I "zstd -T0 -3" -cf "$local_archive_in_pwd" "$source_dir_relative_to_pwd"; then 
            ARCHIVE_SIZE=$(du -sh "$local_archive_in_pwd" | awk '{print $1}')
            echo "æ‰“åŒ…å‹ç¼© $local_archive_in_pwd æˆåŠŸ. æ–‡ä»¶å¤§å°: $ARCHIVE_SIZE" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            echo "å¼€å§‹ä¸Šä¼  $local_archive_in_pwd åˆ° s3://${S3_BUCKET_NAME}/${s3_object_key} ..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            if aws s3 cp "$local_archive_in_pwd" "s3://${S3_BUCKET_NAME}/${s3_object_key}" --quiet; then # Added --quiet
              echo "ä¸Šä¼  $local_archive_in_pwd åˆ° S3 æˆåŠŸã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            else
              echo "é”™è¯¯ï¼šä¸Šä¼  $local_archive_in_pwd åˆ° S3 å¤±è´¥ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            fi
            rm -f "$local_archive_in_pwd" 
          else
            echo "é”™è¯¯ï¼šæ‰“åŒ…å‹ç¼© $source_dir_relative_to_pwd ä¸º $local_archive_in_pwd å¤±è´¥ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          fi
        }
        
        s3_pack_and_upload "$(basename ${{ env.S3_TARGET_STAGING_DIR_PATH }})" "${{ env.S3_STAGING_DIR_ARCHIVE_FILENAME }}"
        s3_pack_and_upload "$(basename ${{ env.S3_TARGET_HOST_BUILD_DIR_PATH }})" "${{ env.S3_HOST_BUILD_DIR_ARCHIVE_FILENAME }}"
        s3_pack_and_upload "$(basename ${{ env.S3_TARGET_TOOLCHAIN_BUILD_DIR_PATH }})" "${{ env.S3_TOOLCHAIN_BUILD_DIR_ARCHIVE_FILENAME }}"
        s3_pack_and_upload "$(basename ${{ env.S3_TARGET_DL_DIR_PATH }})" "${{ env.S3_DL_DIR_ARCHIVE_FILENAME }}"

        if [ -f "$CONFIG_FILE_TO_UPLOAD" ]; then 
          echo "ä¸Šä¼  .config æ–‡ä»¶ (${CONFIG_FILE_TO_UPLOAD}) åˆ° S3..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          S3_CONFIG_OBJECT_KEY="${S3_FULL_PREFIX}/${{ env.S3_CONFIG_SNAPSHOT_FILENAME }}"
          if aws s3 cp "$CONFIG_FILE_TO_UPLOAD" "s3://${S3_BUCKET_NAME}/${S3_CONFIG_OBJECT_KEY}" --quiet; then
            echo ".config æ–‡ä»¶æˆåŠŸä¸Šä¼ åˆ° s3://${S3_BUCKET_NAME}/${S3_CONFIG_OBJECT_KEY}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          else
            echo "é”™è¯¯ï¼šä¸Šä¼  .config æ–‡ä»¶åˆ° S3 å¤±è´¥ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          fi
        else
          echo "è­¦å‘Šï¼š${CONFIG_FILE_TO_UPLOAD} æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ— æ³•ä¸Šä¼ åˆ°S3ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        fi
    # --- END S3 Cache Save ---

    - name: éªŒè¯ Actions Cache é…ç½®å¾…ä¿å­˜ (Verify Actions Cache Save Config)
      if: "!cancelled()"
      run: |
        echo "å·²å®Œæˆç¼–è¯‘å’ŒS3ä¸Šä¼ ã€‚Actions Cache (å°ç¼“å­˜) å°†åœ¨ä½œä¸šç»“æŸæ—¶æ ¹æ®å®šä¹‰çš„keyå’Œpathè‡ªåŠ¨ä¿å­˜ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        df -h | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}

    - name: Upload Debug Logs
      if: always()
      uses: actions/upload-artifact@main
      with:
        name: build-debug-logs-${{ github.run_id }}
        path: |
          ${{ env.DEBUG_LOG_FILE_PATH }}
          ${{ env.CCACHE_LOGFILE_PATH }}
          /workdir/openwrt/logs/
          /workdir/openwrt/config_diff.txt
          /workdir/openwrt/.config
          /workdir/openwrt/.config.input
        retention-days: 7

    - name: æ•´ç†æ–‡ä»¶ (Organize Firmware Files)
      id: organize
      if: steps.compile.outputs.status == 'success' && env.UPLOAD_FIRMWARE == 'true' && !cancelled()
      run: |
        echo "å¼€å§‹æ•´ç†å›ºä»¶æ–‡ä»¶..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
        FIRMWARE_COLLECTION_DIR_PATH="" 
        OPENWRT_BIN_DIR="/workdir/openwrt/bin"
        OPENWRT_TARGETS_DIR="${OPENWRT_BIN_DIR}/targets"

        if [ ! -d "${OPENWRT_TARGETS_DIR}" ]; then
          echo "é”™è¯¯ï¼šç¼–è¯‘ç›®æ ‡ç›®å½• ${OPENWRT_TARGETS_DIR} ä¸å­˜åœ¨ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
          FIRMWARE_COLLECTION_DIR_PATH="/tmp/empty_firmware_collection_$$$(date +%N)" 
          mkdir -p "${FIRMWARE_COLLECTION_DIR_PATH}"
          echo "FIRMWARE=${FIRMWARE_COLLECTION_DIR_PATH}" >> $GITHUB_ENV
          echo "status=success" >> $GITHUB_OUTPUT 
          echo "FIRMWARE_ZIP=${FIRMWARE_COLLECTION_DIR_PATH}.zip" >> $GITHUB_ENV 
          zip -r9 "${FIRMWARE_COLLECTION_DIR_PATH}.zip" "${FIRMWARE_COLLECTION_DIR_PATH}" 
          exit 0
        fi

        DEEPEST_TARGET_SUBDIRS=$(find "${OPENWRT_TARGETS_DIR}" -mindepth 2 -maxdepth 2 -type d ! -name "packages" -print)
        if [ -z "${DEEPEST_TARGET_SUBDIRS}" ]; then
            echo "è­¦å‘Šï¼šåœ¨ ${OPENWRT_TARGETS_DIR} ä¸‹æœªæ‰¾åˆ°æ ‡å‡†çš„ç›®æ ‡æ¶æ„å­ç›®å½•ã€‚å°è¯•ç›´æ¥åœ¨ ${OPENWRT_TARGETS_DIR} æœç´¢ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            DEEPEST_TARGET_SUBDIRS="${OPENWRT_TARGETS_DIR}" 
        fi

        for CURRENT_IMG_SOURCE_DIR in $DEEPEST_TARGET_SUBDIRS; do
            echo "æ£€æŸ¥ç›®å½•: ${CURRENT_IMG_SOURCE_DIR} ä¸­çš„å›ºä»¶æ–‡ä»¶..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            COLLECTED_FIRMWARE_OUTPUT_DIR="${OPENWRT_BIN_DIR}/firmware_collection_$(basename ${CURRENT_IMG_SOURCE_DIR})_$(date +%N)"
            mkdir -p "${COLLECTED_FIRMWARE_OUTPUT_DIR}"
            FILES_COPIED_COUNT=0
            
            cd "${CURRENT_IMG_SOURCE_DIR}" 
            
            for pattern in "*combined.img.gz" "*sysupgrade.img.gz" "*combined-efi.img.gz" "*kernel.bin" "*.img" "*.bin"; do
                find . -maxdepth 1 -type f -name "$pattern" ! -path "./packages/*" -print0 | while IFS= read -r -d $'\0' found_file; do
                    echo "æ‰¾åˆ°æ ‡å‡†å›ºä»¶: ${found_file}ï¼Œå¤åˆ¶åˆ° ${COLLECTED_FIRMWARE_OUTPUT_DIR}/" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                    cp -v -f "${found_file}" "${COLLECTED_FIRMWARE_OUTPUT_DIR}/"
                    FILES_COPIED_COUNT=$((FILES_COPIED_COUNT + 1))
                done
            done
            
            if [ $FILES_COPIED_COUNT -eq 0 ]; then
                echo "åœ¨ ${CURRENT_IMG_SOURCE_DIR} ä¸­æœªæ‰¾åˆ°æ ‡å‡†æ¨¡å¼çš„å›ºä»¶ï¼Œå°è¯•å¤åˆ¶å…¶ä»–å¯èƒ½çš„æ–‡ä»¶..." | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                find . -maxdepth 1 -type f \
                  ! -name "*.manifest" ! -name "*.txt" ! -name "*.json" ! -name "*.buildinfo" ! -name "sha256sums" \
                  ! -path "./packages/*" \
                  -print0 | while IFS= read -r -d $'\0' found_file; do
                    echo "æ‰¾åˆ°å…¶ä»–æ–‡ä»¶: ${found_file}ï¼Œå¤åˆ¶åˆ° ${COLLECTED_FIRMWARE_OUTPUT_DIR}/" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                    cp -v -f "${found_file}" "${COLLECTED_FIRMWARE_OUTPUT_DIR}/"
                    FILES_COPIED_COUNT=$((FILES_COPIED_COUNT + 1))
                done
            fi
            cd "/workdir/openwrt" 

            if [ $FILES_COPIED_COUNT -gt 0 ]; then
                echo "æˆåŠŸä» ${CURRENT_IMG_SOURCE_DIR} å¤åˆ¶ $FILES_COPIED_COUNT ä¸ªæ–‡ä»¶åˆ° ${COLLECTED_FIRMWARE_OUTPUT_DIR}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                if [ -f ".config" ]; then cp -v -f .config "${COLLECTED_FIRMWARE_OUTPUT_DIR}/config.txt"; fi
                ls -lh "${COLLECTED_FIRMWARE_OUTPUT_DIR}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                FIRMWARE_COLLECTION_DIR_PATH="${COLLECTED_FIRMWARE_OUTPUT_DIR}" 
                break 
            else
                echo "è­¦å‘Š: åœ¨ ${CURRENT_IMG_SOURCE_DIR} ä¸­æœªæ‰¾åˆ°å¯ç”¨å›ºä»¶æ–‡ä»¶å¯æ”¶é›†ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                rm -rf "${COLLECTED_FIRMWARE_OUTPUT_DIR}" 
            fi
        done

        if [ -z "${FIRMWARE_COLLECTION_DIR_PATH}" ]; then
            echo "è­¦å‘Šï¼šæœªèƒ½åœ¨ä»»ä½•æ ‡å‡†ç›®æ ‡å­ç›®å½•ä¸­æ”¶é›†åˆ°å›ºä»¶æ–‡ä»¶ã€‚å¯ç”¨ç´§æ€¥å¤‡ç”¨æ”¶é›†é€»è¾‘ã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            FIRMWARE_COLLECTION_DIR_PATH="${OPENWRT_BIN_DIR}/firmware_fallback_collection_$(date +%N)"
            mkdir -p "${FIRMWARE_COLLECTION_DIR_PATH}"
            find "${OPENWRT_TARGETS_DIR}" -type f \( -name "*.bin" -o -name "*.img" -o -name "*.img.gz" \) ! -path "*/packages/*" ! -path "*/firmware_collection_*" -exec cp -v -f {} "${FIRMWARE_COLLECTION_DIR_PATH}/" \;
            if [ -f "/workdir/openwrt/.config" ]; then cp -v -f /workdir/openwrt/.config "${FIRMWARE_COLLECTION_DIR_PATH}/config.txt";
            else echo "# Fallback .config - actual .config not found" > "${FIRMWARE_COLLECTION_DIR_PATH}/config.txt"; fi
        fi

        echo "FIRMWARE=${FIRMWARE_COLLECTION_DIR_PATH}" >> $GITHUB_ENV
        echo "status=success" >> $GITHUB_OUTPUT

        if [ -n "${FIRMWARE_COLLECTION_DIR_PATH}" ] && [ -d "${FIRMWARE_COLLECTION_DIR_PATH}" ] && [ "$(ls -A "${FIRMWARE_COLLECTION_DIR_PATH}")" ]; then
            FIRMWARE_PARENT_DIR=$(dirname "${FIRMWARE_COLLECTION_DIR_PATH}")
            FIRMWARE_BASENAME=$(basename "${FIRMWARE_COLLECTION_DIR_PATH}")
            ZIP_FILENAME="${FIRMWARE_BASENAME}.zip" 
            echo "åˆ›å»ºå›ºä»¶å‹ç¼©åŒ… ${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME} ä»ç›®å½• ${FIRMWARE_BASENAME}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            cd "${FIRMWARE_PARENT_DIR}" && zip -r9 "${ZIP_FILENAME}" "${FIRMWARE_BASENAME}"
            if [ -f "${ZIP_FILENAME}" ]; then
                echo "FIRMWARE_ZIP=${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME}" >> $GITHUB_ENV
                ls -lh "${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME}" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            else
                echo "é”™è¯¯ï¼šå‹ç¼©åŒ… ${ZIP_FILENAME} æœªèƒ½æˆåŠŸåˆ›å»ºã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
                echo "FIRMWARE_ZIP=/tmp/zip_creation_failed_$(date +%N).zip" >> $GITHUB_ENV 
            fi
        else
            echo "è­¦å‘Š: æœ€ç»ˆå›ºä»¶æ”¶é›†ç›®å½• (${FIRMWARE_COLLECTION_DIR_PATH}) æœªæœ‰æ•ˆè®¾ç½®ã€ä¸æ˜¯ç›®å½•æˆ–ä¸ºç©ºï¼Œæ— æ³•åˆ›å»º firmware.zipã€‚" | tee -a ${{ env.DEBUG_LOG_FILE_PATH }}
            echo "FIRMWARE_ZIP=/tmp/no_firmware_to_zip_$(date +%N).zip" >> $GITHUB_ENV
        fi

    - name: ä¸Šä¼ å›ºä»¶ (Artifact)
      uses: actions/upload-artifact@main
      if: steps.organize.outputs.status == 'success' && env.UPLOAD_FIRMWARE == 'true' && !cancelled()
      with:
        name: OpenWrt_firmware${{ env.DEVICE_NAME }}${{ env.FILE_DATE }}
        path: ${{ env.FIRMWARE_ZIP }} 
        if-no-files-found: warn

    - name: ç”Ÿæˆå‘å¸ƒæ ‡ç­¾ (Generate Release Tag)
      id: tag
      if: steps.organize.outputs.status == 'success' && env.UPLOAD_RELEASE == 'true' && !cancelled()
      run: |
        RELEASE_TAG_BASE=$(date +"%Y.%m.%d-%H%M")
        DEVICE_TAG_PART=$(echo "${{ env.DEVICE_NAME }}" | sed 's/^_//;s/_$//' | sed 's/[^a-zA-Z0-9._-]/-/g' )
        if [ -n "$DEVICE_TAG_PART" ] && [ "$DEVICE_TAG_PART" != "-" ]; then FINAL_RELEASE_TAG="${RELEASE_TAG_BASE}_${DEVICE_TAG_PART}"; else FINAL_RELEASE_TAG="${RELEASE_TAG_BASE}"; fi
        echo "RELEASE_TAG=${FINAL_RELEASE_TAG}" >> $GITHUB_OUTPUT
        echo "## OpenWrt Firmware Build ($(date +"%Y-%m-%d %H:%M %Z")) ğŸ“¦" > release_body.txt
        echo "" >> release_body.txt
        echo "**Branch:** \`${{ env.REPO_BRANCH }}\`" >> release_body.txt
        echo "**Config:** \`${{ env.CONFIG_FILE_NAME }}\`" >> release_body.txt
        if [ -n "$DEVICE_TAG_PART" ] && [ "$DEVICE_TAG_PART" != "-" ]; then echo "**Device:** \`${{ env.DEVICE_NAME }}\`" >> release_body.txt; fi
        echo "" >> release_body.txt
        echo "### å›ºä»¶ä¸‹è½½ (Firmware Download)" >> release_body.txt
        echo "è¯·åœ¨ä¸‹æ–¹ Assets ä¸­æ‰¾åˆ°å›ºä»¶æ–‡ä»¶ (é€šå¸¸æ˜¯ä¸€ä¸ª .zip å‹ç¼©åŒ…)ã€‚" >> release_body.txt
        echo "Please find firmware files (usually a .zip archive) in the Assets section below." >> release_body.txt
        echo "" >> release_body.txt; echo "---" >> release_body.txt
        echo "âš ï¸ **åˆ·æœºå‰è¯·åŠ¡å¿…å¤‡ä»½é‡è¦æ•°æ®ï¼**" >> release_body.txt
        echo "âš ï¸ **Backup your important data before flashing!**" >> release_body.txt
        echo "" >> release_body.txt
        echo "_Built by GitHub Actions - Workflow: [${{ github.workflow }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})_" >> release_body.txt
        echo "status=success" >> $GITHUB_OUTPUT

    - name: ä¸Šä¼ å›ºä»¶åˆ°Releases (Upload Firmware to Releases)
      uses: softprops/action-gh-release@v2
      if: steps.tag.outputs.status == 'success' && !cancelled()
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ steps.tag.outputs.RELEASE_TAG }}
        body_path: release_body.txt
        files: ${{ env.FIRMWARE_ZIP }} 

    - name: åˆ é™¤æ—§çš„Releases (Delete Old Releases)
      uses: dev-drprasad/delete-older-releases@master
      if: env.UPLOAD_RELEASE == 'true' && !cancelled()
      with:
        keep_latest: 3
        delete_tags: true
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
