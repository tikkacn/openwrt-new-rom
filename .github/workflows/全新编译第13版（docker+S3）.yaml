name: å…¨æ–°ç¼–è¯‘ç¬¬13ç‰ˆ(Docker-S3FullEnvCache)

on:
  workflow_dispatch:
    inputs:
      ssh:
        description: 'SSHè°ƒè¯• (åœ¨Dockerå®¹å™¨å†…éƒ¨)'
        required: false
        default: 'false'
      clean_build:
        description: 'å…¨æ–°ç¼–è¯‘ï¼Œä¸ä½¿ç”¨S3æ¢å¤çš„ç¯å¢ƒã€‚ä»ä¼šæ‰“åŒ…ä¸Šä¼ æ–°ç¯å¢ƒåˆ°S3ã€‚é¦–æ¬¡S3å¡«å……æ—¶åº”ä¸ºfalseå¹¶é¢„æ¸…ç©ºS3ã€‚'
        required: false
        default: 'false' 
      config_file:
        description: 'é…ç½®æ–‡ä»¶å (ä½äºä»“åº“æ ¹ç›®å½•)'
        required: false
        default: 'å¢é‡ç¼“å­˜ä¼˜åŒ–.config'

env:
  REPO_URL: https://github.com/coolsnowwolf/lede
  REPO_BRANCH: master 
  FEEDS_CONF_URL: https://github.com/tikkacn/openwrt-new-rom/raw/main/feeds.conf.default
  CONFIG_FILE_IN_REPO: ${{ github.event.inputs.config_file || 'å¢é‡ç¼“å­˜ä¼˜åŒ–.config' }} # åœ¨ä»“åº“ä¸­çš„é…ç½®æ–‡ä»¶å
  DIY_P1_SH_IN_REPO: diy-part1.sh 
  DIY_P2_SH_IN_REPO: diy-part2.sh 
  UPLOAD_FIRMWARE: true
  UPLOAD_RELEASE: true
  TZ: Asia/Shanghai

  # Docker å’Œ S3 ç›¸å…³è®¾ç½®
  DOCKER_IMAGE: ubuntu:22.04 # ä½¿ç”¨çš„åŸºç¡€Dockeré•œåƒ
  # RUNNER_WORKSPACE_MOUNT_POINT: /workdir_runner # Runnerä¸Šçš„ /workdir æŒ‚è½½ç‚¹ (ç”±maximize-build-spaceåˆ›å»º)
  # OPENWRT_BASE_ON_RUNNER: /workdir/openwrt_build_environment # Runnerä¸Šå­˜æ”¾æ•´ä¸ªOpenWrtå·¥ä½œåŒºçš„ç›®å½•
  # CONTAINER_WORKING_DIR: /build # Dockerå®¹å™¨å†…çš„å·¥ä½œç›®å½•
  # CONTAINER_REPO_CONFIG_PATH: /repo_config # å®¹å™¨å†…æ˜ å°„çš„ä»“åº“æ ¹ç›®å½•ï¼Œç”¨äºè¯»å–configå’ŒDIYè„šæœ¬

  # S3 ç¼“å­˜å‹ç¼©åŒ…ä¿¡æ¯
  S3_WORKSPACE_ARCHIVE_FILENAME: openwrt_workspace_cache.tar.zst # æ•´ä¸ªå·¥ä½œåŒºçš„S3ç¼“å­˜æ–‡ä»¶å
  S3_PATH_PREFIX: ${{ secrets.S3_CACHE_PATH_PREFIX || format('openwrt-s3env-caches/{0}', env.REPO_BRANCH) }} # S3æ¡¶å†…è·¯å¾„å‰ç¼€
  S3_CONFIG_SNAPSHOT_FILENAME: last_successful_build.config # S3ä¸Šä¿å­˜çš„.configå¿«ç…§æ–‡ä»¶å

  # æ—¥å¿—æ–‡ä»¶è·¯å¾„ (è¿™äº›å°†åœ¨Dockerå®¹å™¨å†…éƒ¨ä½¿ç”¨)
  CONTAINER_CCACHE_LOGFILE_PATH: /tmp/ccache_detailed.log
  CONTAINER_DEBUG_LOG_FILE_PATH: /tmp/build_debug_summary.log
  
  # ç¼–è¯‘ç›¸å…³çš„ç›®å½•ï¼Œç›¸å¯¹äºå®¹å™¨å†…çš„OpenWrtæ ¹ç›®å½• (ä¾‹å¦‚ /build/openwrt)
  # è¿™äº›ä»…ç”¨äºä¿¡æ¯å±•ç¤ºæˆ–å†…éƒ¨è„šæœ¬ï¼Œå®é™…ç¼“å­˜æ˜¯æ•´ä¸ªå·¥ä½œåŒº
  BUILD_STATE_DIR_NAME: .github_actions_build_state # å­˜æ”¾åœ¨OpenWrtæ ¹ç›®å½•ä¸‹
  CCACHE_DIR_NAME: .ccache # ccacheç›®å½•ä¹Ÿæ”¾åœ¨OpenWrtæ ¹ç›®å½•ä¸‹ï¼Œéšæ•´ä¸ªç¯å¢ƒç¼“å­˜

jobs:
  build_in_docker:
    runs-on: ubuntu-22.04
    name: Build OpenWrt in Docker with S3 Env Cache

    env: # Job specific env
      RUNNER_OPENWRT_WORKSPACE: /workdir/openwrt_s3_env # Runnerä¸Šè§£å‹/æ‰“åŒ…S3ç¼“å­˜çš„åŒºåŸŸ
      CONTAINER_BUILD_AREA: /build_area # å®¹å™¨å†…OpenWrtæºç å’Œæ„å»ºçš„æ ¹ç›®å½•
      CONTAINER_REPO_CONFIG_MOUNT: /repo_config # å®¹å™¨å†…æ˜ å°„çš„GitHubä»“åº“æ ¹ç›®å½•

    steps:
    - name: æ£€å‡ºä»“åº“ä»£ç  (Checkout Repository Code)
      uses: actions/checkout@v4
      with:
        path: ${{ env.CONTAINER_REPO_CONFIG_MOUNT }} # å°†ä»“åº“ä»£ç æ£€å‡ºåˆ°ç‰¹å®šè·¯å¾„ï¼Œä»¥ä¾¿åç»­æ˜ å°„åˆ°Docker

    - name: è®¾ç½® S3 ç¼“å­˜çš„å®Œæ•´è·¯å¾„å‰ç¼€ (Set Full S3 Cache Path Prefix)
      id: set_s3_vars
      run: |
        s3_prefix_from_secret="${{ secrets.S3_CACHE_PATH_PREFIX }}"
        repo_branch_for_path="${{ env.REPO_BRANCH }}"
        # æ›¿æ¢åˆ†æ”¯åä¸­çš„ / ä¸º - , é¿å…S3è·¯å¾„é—®é¢˜
        repo_branch_for_path_sanitized=$(echo "$repo_branch_for_path" | sed 's/\//-/g')
        
        final_s3_prefix=""
        if [ -n "$s3_prefix_from_secret" ]; then
          final_s3_prefix="$s3_prefix_from_secret"
          echo "ä½¿ç”¨æ¥è‡ª Secret 'S3_CACHE_PATH_PREFIX' çš„S3è·¯å¾„å‰ç¼€: $final_s3_prefix"
        else
          default_prefix="openwrt-s3env-caches/${repo_branch_for_path_sanitized}"
          final_s3_prefix="$default_prefix"
          echo "ä½¿ç”¨é»˜è®¤S3è·¯å¾„å‰ç¼€: $final_s3_prefix"
        fi
        echo "S3_EFFECTIVE_PATH_PREFIX=${final_s3_prefix}" >> $GITHUB_ENV
        echo "s3_prefix_out=${final_s3_prefix}" >> $GITHUB_OUTPUT
        echo "DEBUG_LOG_ON_RUNNER=${{ env.CONTAINER_REPO_CONFIG_MOUNT }}/build_debug_summary_runner.log" >> $GITHUB_ENV # Runnerä¸Šçš„è°ƒè¯•æ—¥å¿—

    - name: ä¼˜åŒ–Runnerç£ç›˜ç©ºé—´ (Maximize Runner Build Space)
      uses: easimon/maximize-build-space@master
      with:
        root-reserve-mb: 10240 
        swap-size-mb: 2048
        remove-dotnet: 'true'
        remove-android: 'true'
        remove-haskell: 'true'
        remove-codeql: 'true'
        remove-docker-images: 'false' # Dockeré•œåƒæ˜¯éœ€è¦çš„
        build-mount-path: '/workdir' # Runnerä¸Šçš„å·¥ä½œåŒºï¼Œè§£å‹çš„S3ç¼“å­˜å°†æ”¾åœ¨è¿™é‡Œé¢

    - name: é…ç½® AWS å‡­è¯ (Configure AWS Credentials)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: ä¸‹è½½å¹¶æ¢å¤S3æ„å»ºç¯å¢ƒç¼“å­˜ (Download & Restore S3 Build Env Cache)
      if: inputs.clean_build != 'true'
      env: # Pass necessary env vars to this step
          S3_BUCKET_NAME_SECRET: ${{ secrets.AWS_S3_BUCKET_NAME }}
          S3_ARCHIVE_NAME_ENV: ${{ env.S3_WORKSPACE_ARCHIVE_FILENAME }}
          RUNNER_WORKSPACE_PATH_ENV: ${{ env.RUNNER_OPENWRT_WORKSPACE }}
          DEBUG_LOG_FILE: ${{ env.DEBUG_LOG_ON_RUNNER }}
      run: |
        echo "S3_EFFECTIVE_PATH_PREFIX in download step: ${{ env.S3_EFFECTIVE_PATH_PREFIX }}" | tee -a $DEBUG_LOG_FILE
        if [ -z "$S3_BUCKET_NAME_SECRET" ]; then
          echo "[ERROR] AWS_S3_BUCKET_NAME secret æœªè®¾ç½®ã€‚è·³è¿‡S3ç¼“å­˜æ¢å¤ã€‚" | tee -a $DEBUG_LOG_FILE
          mkdir -p $RUNNER_WORKSPACE_PATH_ENV # ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå³ä½¿æ˜¯ç©ºçš„
          exit 0 
        fi
        
        S3_OBJECT_KEY="${{ env.S3_EFFECTIVE_PATH_PREFIX }}/${S3_ARCHIVE_NAME_ENV}"
        LOCAL_ARCHIVE_ON_RUNNER="/tmp/${S3_ARCHIVE_NAME_ENV}" # ä¸‹è½½åˆ°Runnerçš„/tmp

        echo "å°è¯•ä» S3 ä¸‹è½½: s3://${S3_BUCKET_NAME_SECRET}/${S3_OBJECT_KEY} åˆ° ${LOCAL_ARCHIVE_ON_RUNNER} ..." | tee -a $DEBUG_LOG_FILE
        if aws s3 cp "s3://${S3_BUCKET_NAME_SECRET}/${S3_OBJECT_KEY}" "${LOCAL_ARCHIVE_ON_RUNNER}" --no-progress; then
          echo "ä¸‹è½½ ${S3_ARCHIVE_NAME_ENV} æˆåŠŸ. å¤§å°: $(du -sh ${LOCAL_ARCHIVE_ON_RUNNER} | awk '{print $1}')" | tee -a $DEBUG_LOG_FILE
          echo "å¼€å§‹è§£å‹åˆ° ${RUNNER_WORKSPACE_PATH_ENV} ..." | tee -a $DEBUG_LOG_FILE
          mkdir -p "${RUNNER_WORKSPACE_PATH_ENV}"
          # è§£å‹å‰åˆ é™¤æ—§å†…å®¹
          rm -rf "${RUNNER_WORKSPACE_PATH_ENV:?}"/* "${RUNNER_WORKSPACE_PATH_ENV:?}"/.[!.]* "${RUNNER_WORKSPACE_PATH_ENV:?}"/..?* 2>/dev/null || true
          if tar -I "zstd -T0" -xf "${LOCAL_ARCHIVE_ON_RUNNER}" -C "${RUNNER_WORKSPACE_PATH_ENV}"; then 
            echo "è§£å‹ ${S3_ARCHIVE_NAME_ENV} åˆ° ${RUNNER_WORKSPACE_PATH_ENV} æˆåŠŸã€‚" | tee -a $DEBUG_LOG_FILE
            echo "S3_CACHE_RESTORED=true" >> $GITHUB_ENV
          else
            echo "é”™è¯¯ï¼šè§£å‹ ${S3_ARCHIVE_NAME_ENV} å¤±è´¥ã€‚å°†è¿›è¡Œå…¨æ–°æ„å»ºã€‚" | tee -a $DEBUG_LOG_FILE
            rm -rf "${RUNNER_WORKSPACE_PATH_ENV:?}"/* "${RUNNER_WORKSPACE_PATH_ENV:?}"/.[!.]* "${RUNNER_WORKSPACE_PATH_ENV:?}"/..?* 2>/dev/null || true # æ¸…ç†ä¸å®Œæ•´çš„è§£å‹
          fi
          rm -f "${LOCAL_ARCHIVE_ON_RUNNER}" 
        else
          echo "ä» S3 ä¸‹è½½ ${S3_ARCHIVE_NAME_ENV} å¤±è´¥æˆ–æ–‡ä»¶ä¸å­˜åœ¨ã€‚å°†è¿›è¡Œå…¨æ–°æ„å»ºã€‚" | tee -a $DEBUG_LOG_FILE
          mkdir -p $RUNNER_WORKSPACE_PATH_ENV # ç¡®ä¿ç›®å½•å­˜åœ¨
        fi
        df -h | tee -a $DEBUG_LOG_FILE

    - name: è¿è¡ŒDockerå®¹å™¨å¹¶æ‰§è¡Œç¼–è¯‘ (Run Docker Container & Compile)
      id: compile_in_docker
      # RUNNER_OPENWRT_WORKSPACE (e.g., /workdir/openwrt_s3_env) is mounted to CONTAINER_BUILD_AREA (e.g., /build_area)
      # GITHUB_WORKSPACE (e.g., /home/runner/work/repo/repo/repo_config) is mounted to CONTAINER_REPO_CONFIG_MOUNT (e.g., /repo_config)
      # All paths inside the script are relative to CONTAINER_BUILD_AREA or use CONTAINER_REPO_CONFIG_MOUNT
      run: |
        # Docker run command
        # It will execute a script that is heredoc'd or passed as a file
        # The script needs to handle both S3 cache hit and miss scenarios

        # Define paths used inside the container
        CONTAINER_BUILD_AREA="${{ env.CONTAINER_BUILD_AREA }}"
        CONTAINER_REPO_CONFIG_PATH="${{ env.CONTAINER_REPO_CONFIG_MOUNT }}"
        
        # Prepare the script to be run inside Docker
        cat << 'DOCKER_SCRIPT_EOF' > /tmp/docker_build_script.sh
        #!/bin/bash
        set -eo pipefail # Exit on error, treat unset vars as error, pipefail

        echo "[DOCKER] Starting build script inside Docker container..."
        echo "[DOCKER] Runner's OpenWrt Workspace (mounted at ${CONTAINER_BUILD_AREA}): $(ls -A ${CONTAINER_BUILD_AREA} | wc -l) items"
        echo "[DOCKER] Repo Config Path (mounted at ${CONTAINER_REPO_CONFIG_PATH}): $(ls -A ${CONTAINER_REPO_CONFIG_PATH} | wc -l) items"

        # Ensure essential tools are available
        apt-get update -y && apt-get install -y --no-install-recommends \
          git build-essential libncurses5-dev libncursesw5-dev zlib1g-dev libssl-dev \
          subversion gawk wget curl python3 python3-distutils unzip file patch \
          rsync util-linux procps ccache libelf-dev libfuse-dev libglib2.0-dev \
          libgmp3-dev libltdl-dev libmpc-dev libmpfr-dev libreadline-dev libtool \
          llvm p7zip p7zip-full xsltproc xxd gettext autopoint \
          time # For timing make if needed
        apt-get clean && rm -rf /var/lib/apt/lists/*
        
        # Set Timezone inside container
        export TZ="${BUILD_TZ:-Asia/Shanghai}"
        ln -snf "/usr/share/zoneinfo/$TZ" /etc/localtime && echo "$TZ" > /etc/timezone
        
        # Navigate to the build area
        mkdir -p "${CONTAINER_BUILD_AREA}"
        cd "${CONTAINER_BUILD_AREA}"
        echo "[DOCKER] Current directory: $(pwd)"

        # Define internal paths (these are now relative to CONTAINER_BUILD_AREA or absolute within container)
        INTERNAL_BUILD_STATE_DIR="./${BUILD_STATE_DIR_NAME:-.github_actions_build_state}" # e.g. /build_area/.gh_actions_build_state
        INTERNAL_CCACHE_DIR="./${CCACHE_DIR_NAME:-.ccache}" # e.g. /build_area/.ccache
        INTERNAL_CONFIG_FILE_NAME="${CONFIG_FILE_NAME_IN_REPO:-.config_default}" # Copied from /repo_config
        INTERNAL_DIY_P1_SH_NAME="${DIY_P1_SH_NAME_IN_REPO:-diy-p1-default.sh}"
        INTERNAL_DIY_P2_SH_NAME="${DIY_P2_SH_NAME_IN_REPO:-diy-p2-default.sh}"
        INTERNAL_DEBUG_LOG="${CONTAINER_DEBUG_LOG_PATH:-/tmp/container_build_debug.log}"
        INTERNAL_CCACHE_LOG="${CONTAINER_CCACHE_LOG_PATH:-/tmp/container_ccache_detailed.log}"

        # Setup ccache
        mkdir -p "${INTERNAL_CCACHE_DIR}"
        export CCACHE_DIR="${INTERNAL_CCACHE_DIR}"
        export CCACHE_LOGFILE="${INTERNAL_CCACHE_LOG}"
        ccache -M 8G # Set max size
        ccache -z   # Zero stats for this run

        # Check if this is a fresh clone (S3 cache miss / clean_build) or restored env
        # A simple check could be the existence of .git directory or a specific OpenWrt file
        if [ ! -d ".git" ] && [ ! -f "Makefile" ]; then # Assuming S3 cache would contain a populated OpenWrt tree
            echo "[DOCKER] Looks like a fresh setup (no .git or Makefile in ${CONTAINER_BUILD_AREA}). Cloning OpenWrt..." | tee -a "${INTERNAL_DEBUG_LOG}"
            git clone --depth 1 "${REPO_URL_ENV}" -b "${REPO_BRANCH_ENV}" . # Clone into current dir (${CONTAINER_BUILD_AREA})
            FRESH_CLONE="true"
        else
            echo "[DOCKER] Found existing OpenWrt tree in ${CONTAINER_BUILD_AREA} (likely restored from S3 cache)." | tee -a "${INTERNAL_DEBUG_LOG}"
            # Optional: git pull to update source if cache is old? Or rely on S3 cache being the "golden" state.
            # For now, assume S3 cache is the state we want to build upon.
            # git checkout -f "${REPO_BRANCH_ENV}"
            # git pull origin "${REPO_BRANCH_ENV}" --ff-only --depth 1 || echo "Git pull failed or not fast-forward"
            FRESH_CLONE="false"
        fi
        
        # Ensure all necessary subdirectories for build state and ccache exist
        mkdir -p "${INTERNAL_BUILD_STATE_DIR}"
        mkdir -p "${INTERNAL_CCACHE_DIR}" # ccache dir is within the build area now
        mkdir -p logs

        # Copy config and DIY scripts from the repo checkout (mounted at /repo_config)
        echo "[DOCKER] Copying config and DIY scripts from ${CONTAINER_REPO_CONFIG_PATH} ..." | tee -a "${INTERNAL_DEBUG_LOG}"
        cp "${CONTAINER_REPO_CONFIG_PATH}/${CONFIG_FILE_NAME_IN_REPO}" "./.config"
        cp ./.config ./.config.input # Save a copy of the input .config
        
        # Ensure DIY scripts exist even if empty from repo, make them executable
        cp "${CONTAINER_REPO_CONFIG_PATH}/${DIY_P1_SH_NAME_IN_REPO}" "./${DIY_P1_SH_NAME_IN_REPO}" && chmod +x "./${DIY_P1_SH_NAME_IN_REPO}"
        cp "${CONTAINER_REPO_CONFIG_PATH}/${DIY_P2_SH_NAME_IN_REPO}" "./${DIY_P2_SH_NAME_IN_REPO}" && chmod +x "./${DIY_P2_SH_NAME_IN_REPO}"
        
        # Run DIY script part 1 (before feeds)
        "./${DIY_P1_SH_NAME_IN_REPO}"

        echo "[DOCKER] Setting up feeds using ${CONTAINER_REPO_CONFIG_PATH}/feeds.conf.default (if it exists, else use OpenWrt default)..." | tee -a "${INTERNAL_DEBUG_LOG}"
        if [ -f "${CONTAINER_REPO_CONFIG_PATH}/feeds.conf.default" ]; then # Check if custom feeds.conf.default exists in repo
          cp "${CONTAINER_REPO_CONFIG_PATH}/feeds.conf.default" "./feeds.conf.default"
        elif [ ! -f "./feeds.conf.default" ] && [ -f "./feeds.conf.default.sample" ]; then # If no custom and no default, use sample
          cp feeds.conf.default.sample feeds.conf.default 
        fi
        cat feeds.conf.default | tee -a "${INTERNAL_DEBUG_LOG}"

        ./scripts/feeds update -a
        ./scripts/feeds install -a

        # Run DIY script part 2 (after feeds, before make defconfig)
        "./${DIY_P2_SH_NAME_IN_REPO}"
        
        # Standard .config adjustments
        echo "CONFIG_AUTOREMOVE=y" >> .config 
        echo "CONFIG_AUTOREBUILD=y" >> .config 
        # (Ensuring image options logic as before)
        if ! grep -q "CONFIG_TARGET_ROOTFS_SQUASHFS=y" .config; then echo "CONFIG_TARGET_ROOTFS_SQUASHFS=y" >> .config; fi
        if ! grep -q "CONFIG_TARGET_IMAGES_GZIP=y" .config; then echo "CONFIG_TARGET_IMAGES_GZIP=y" >> .config; fi
        # ... etc. for other essential image options

        echo "[DOCKER] Running make defconfig..." | tee -a "${INTERNAL_DEBUG_LOG}"
        make defconfig
        
        # (Missing package recovery logic as before)
        # ...

        # --- Build decision logic (MD5s from .config, feeds_changed from env) ---
        # This now uses the .config within the container and build_state within the container
        TOOLCHAIN_CONFIG_SUBSET_FOR_MD5=$(grep -E "^CONFIG_TARGET|^CONFIG_ARCH|^CONFIG_TOOLCHAIN" .config | grep -v "NOT_SET" | sort)
        TOOLCHAIN_MD5=$(echo "$TOOLCHAIN_CONFIG_SUBSET_FOR_MD5" | md5sum | awk '{print $1}')
        PREVIOUS_TOOLCHAIN_MD5=$(cat ${INTERNAL_BUILD_STATE_DIR}/toolchain.md5 2>/dev/null || echo "not_found_in_build_state")

        PACKAGE_CONFIG_SUBSET_FOR_MD5=$(grep "^CONFIG_PACKAGE_" .config | grep "=y" | sort) 
        PACKAGE_MD5=$(echo "$PACKAGE_CONFIG_SUBSET_FOR_MD5" | md5sum | awk '{print $1}')
        PREVIOUS_PACKAGE_MD5=$(cat ${INTERNAL_BUILD_STATE_DIR}/package.md5 2>/dev/null || echo "not_found_in_build_state")
        
        # Feeds changed status needs to be passed into Docker or re-calculated if feeds source is also in S3 cache
        # For now, let's assume FEEDS_CHANGED_FROM_OUTSIDE is passed as an env var to docker run
        DO_FULL_BUILD_DOCKER=0
        DO_PACKAGE_BUILD_DOCKER=0

        echo "[DOCKER] --- Build Decision Variables ---" | tee -a "${INTERNAL_DEBUG_LOG}"
        echo "[DOCKER] Input clean_build (from outside): ${CLEAN_BUILD_FROM_OUTSIDE}" | tee -a "${INTERNAL_DEBUG_LOG}"
        echo "[DOCKER] S3 Cache Restored (from outside): ${S3_CACHE_RESTORED_FROM_OUTSIDE}" | tee -a "${INTERNAL_DEBUG_LOG}"
        echo "[DOCKER] Current TOOLCHAIN_MD5: $TOOLCHAIN_MD5" | tee -a "${INTERNAL_DEBUG_LOG}"
        echo "[DOCKER] Previous TOOLCHAIN_MD5: $PREVIOUS_TOOLCHAIN_MD5" | tee -a "${INTERNAL_DEBUG_LOG}"
        echo "[DOCKER] Current PACKAGE_MD5: $PACKAGE_MD5" | tee -a "${INTERNAL_DEBUG_LOG}"
        echo "[DOCKER] Previous PACKAGE_MD5: $PREVIOUS_PACKAGE_MD5" | tee -a "${INTERNAL_DEBUG_LOG}"
        echo "[DOCKER] Feeds changed (from outside): ${FEEDS_CHANGED_FROM_OUTSIDE}" | tee -a "${INTERNAL_DEBUG_LOG}"

        if [ "${CLEAN_BUILD_FROM_OUTSIDE}" = "true" ] || [ "${S3_CACHE_RESTORED_FROM_OUTSIDE}" != "true" ] ; then
          echo "[DOCKER] clean_build is true OR S3 cache not restored: DO_FULL_BUILD_DOCKER=1" | tee -a "${INTERNAL_DEBUG_LOG}"
          DO_FULL_BUILD_DOCKER=1
        elif [ "$PREVIOUS_TOOLCHAIN_MD5" = "not_found_in_build_state" ] || [ "$TOOLCHAIN_MD5" != "$PREVIOUS_TOOLCHAIN_MD5" ]; then
          echo "[DOCKER] Toolchain config MD5 changed or first build state: DO_FULL_BUILD_DOCKER=1" | tee -a "${INTERNAL_DEBUG_LOG}"
          DO_FULL_BUILD_DOCKER=1
        elif [ "$PREVIOUS_PACKAGE_MD5" = "not_found_in_build_state" ] || [ "$PACKAGE_MD5" != "$PREVIOUS_PACKAGE_MD5" ]; then
          echo "[DOCKER] Package config MD5 changed: DO_PACKAGE_BUILD_DOCKER=1" | tee -a "${INTERNAL_DEBUG_LOG}"
          DO_PACKAGE_BUILD_DOCKER=1
        elif [ "${FEEDS_CHANGED_FROM_OUTSIDE}" = "true" ]; then
           echo "[DOCKER] Feeds changed: DO_PACKAGE_BUILD_DOCKER=1" | tee -a "${INTERNAL_DEBUG_LOG}"
           DO_PACKAGE_BUILD_DOCKER=1
        fi
        echo "[DOCKER] Final Build Strategy -> DO_FULL_BUILD_DOCKER: $DO_FULL_BUILD_DOCKER, DO_PACKAGE_BUILD_DOCKER: $DO_PACKAGE_BUILD_DOCKER" | tee -a "${INTERNAL_DEBUG_LOG}"
        
        # Compile Firmware (similar to previous compile_firmware function)
        MAKE_JOBS_DOCKER=$(nproc)
        MAIN_MAKE_CMD_DOCKER="make -j${MAKE_JOBS_DOCKER} V=s"
        FALLBACK_MAKE_CMD_DOCKER="make -j1 V=s"
        COMPILE_OUTPUT_LOG_DOCKER="logs/compile_output_docker_$(date +%Y%m%d_%H%M%S).log"
        echo "[DOCKER] Detailed compile log will be in: ${CONTAINER_BUILD_AREA}/${COMPILE_OUTPUT_LOG_DOCKER}" | tee -a "${INTERNAL_DEBUG_LOG}"

        if [ $DO_FULL_BUILD_DOCKER -eq 1 ]; then
          echo "[DOCKER] --- Compile Branch: Full Build ---" | tee -a "${INTERNAL_DEBUG_LOG}"
          make tools/compile $FALLBACK_MAKE_CMD_DOCKER || make tools/compile $FALLBACK_MAKE_CMD_DOCKER
          make toolchain/compile $FALLBACK_MAKE_CMD_DOCKER || make toolchain/compile $FALLBACK_MAKE_CMD_DOCKER
          echo "[DOCKER] Starting full world compile..." | tee -a "${INTERNAL_DEBUG_LOG}"
          if ! $MAIN_MAKE_CMD_DOCKER 2>&1 | tee "${COMPILE_OUTPUT_LOG_DOCKER}"; then $FALLBACK_MAKE_CMD_DOCKER 2>&1 | tee -a "${COMPILE_OUTPUT_LOG_DOCKER}"; fi
        elif [ $DO_PACKAGE_BUILD_DOCKER -eq 1 ]; then
          echo "[DOCKER] --- Compile Branch: Package Build ---" | tee -a "${INTERNAL_DEBUG_LOG}"
          make package/clean V=s || true
          if ! make package/compile $MAIN_MAKE_CMD_DOCKER 2>&1 | tee "${COMPILE_OUTPUT_LOG_DOCKER}"; then make package/compile $FALLBACK_MAKE_CMD_DOCKER 2>&1 | tee -a "${COMPILE_OUTPUT_LOG_DOCKER}"; fi
          make package/index V=s || make package/index $FALLBACK_MAKE_CMD_DOCKER
        else
          echo "[DOCKER] --- Compile Branch: Minimal Incremental Build ---" | tee -a "${INTERNAL_DEBUG_LOG}"
          if ! $MAIN_MAKE_CMD_DOCKER 2>&1 | tee "${COMPILE_OUTPUT_LOG_DOCKER}"; then $FALLBACK_MAKE_CMD_DOCKER 2>&1 | tee -a "${COMPILE_OUTPUT_LOG_DOCKER}"; fi
        fi
        
        echo "[DOCKER] Finalizing target/install..." | tee -a "${INTERNAL_DEBUG_LOG}"
        make target/install $FALLBACK_MAKE_CMD_DOCKER 2>&1 | tee -a "${COMPILE_OUTPUT_LOG_DOCKER}"
        final_install_status_docker=$?

        # Explicit stamp finalization (as discussed)
        echo "[DOCKER] Attempting to finalize core component stamps..." | tee -a "${INTERNAL_DEBUG_LOG}"
        make prepare -j${MAKE_JOBS_DOCKER} V=s || make prepare -j1 V=s || echo "[DOCKER_WARN] 'make prepare' had issues." | tee -a "${INTERNAL_DEBUG_LOG}"
        make tools/install -j${MAKE_JOBS_DOCKER} V=s IGNORE_ERRORS=m || make tools/install -j1 V=s IGNORE_ERRORS=m || echo "[DOCKER_WARN] 'make tools/install' had issues." | tee -a "${INTERNAL_DEBUG_LOG}"
        make toolchain/install -j${MAKE_JOBS_DOCKER} V=s IGNORE_ERRORS=m || make toolchain/install -j1 V=s IGNORE_ERRORS=m || echo "[DOCKER_WARN] 'make toolchain/install' had issues." | tee -a "${INTERNAL_DEBUG_LOG}"
        echo "[DOCKER] Core component stamp finalization attempted." | tee -a "${INTERNAL_DEBUG_LOG}"

        # Save MD5s to the build_state dir *inside* the build area
        mkdir -p "${INTERNAL_BUILD_STATE_DIR}"
        cp .config "${INTERNAL_BUILD_STATE_DIR}/config_from_compile_step.txt"
        echo "$TOOLCHAIN_MD5" > "${INTERNAL_BUILD_STATE_DIR}/toolchain.md5"
        echo "$PACKAGE_MD5" > "${INTERNAL_BUILD_STATE_DIR}/package.md5"
        # Save feeds hash from outside, or recalculate if feeds source is also part of workspace
        echo "${FEEDS_CHANGED_FROM_OUTSIDE}" > "${INTERNAL_BUILD_STATE_DIR}/last_feeds_changed_status.txt" 
        find feeds -type f -name "Makefile" -exec sha256sum {} \; | sort | sha256sum > "${INTERNAL_BUILD_STATE_DIR}/current_feeds.sha256"

        echo "[DOCKER] >>> CCACHE Statistics at END of compile_firmware:" | tee -a "${INTERNAL_DEBUG_LOG}"
        ccache -s | tee -a "${INTERNAL_DEBUG_LOG}"

        if [ ${final_install_status_docker} -eq 0 ] && [ -n "$(find bin/targets -type f \( -name "*.bin" -o -name "*combined*" -o -name "*sysupgrade*" -o -name "*.img.gz" \) -print -quit)" ]; then
          echo "[DOCKER] Compile firmware successful." | tee -a "${INTERNAL_DEBUG_LOG}"
          # Create a success marker file for the outer script to check
          touch /tmp/docker_build_success 
        else
          echo "[DOCKER] Compile firmware failed." | tee -a "${INTERNAL_DEBUG_LOG}"
          # Create a failure marker file
          touch /tmp/docker_build_failure
        fi
        # Copy docker debug log to the mounted repo_config for upload if something goes wrong with workspace upload
        cp "${INTERNAL_DEBUG_LOG}" "${CONTAINER_REPO_CONFIG_PATH}/docker_build_debug_summary.log" || true
        cp "${INTERNAL_CCACHE_LOG}" "${CONTAINER_REPO_CONFIG_PATH}/docker_ccache_detailed.log" || true
        # Copy main make log also
        if [ -f "${COMPILE_OUTPUT_LOG_DOCKER}" ]; then
          cp "${COMPILE_OUTPUT_LOG_DOCKER}" "${CONTAINER_REPO_CONFIG_PATH}/docker_compile_output.log" || true
        fi

        echo "[DOCKER] Build script finished."
        DOCKER_SCRIPT_EOF
        chmod +x /tmp/docker_build_script.sh

        # Run the Docker container
        # Pass necessary env vars from the outside workflow into the Docker container
        # S3_CACHE_RESTORED_FROM_OUTSIDE from previous step output (if possible, else check dir existence in script)
        # FEEDS_CHANGED_FROM_OUTSIDE from env.feeds_changed
        # CLEAN_BUILD_FROM_OUTSIDE from inputs.clean_build
        # Note: GITHUB_ENV is not directly accessible inside docker run script in this way.
        #       Status has to be communicated via files or exit codes.
        docker run --rm \
          -v "${{ env.RUNNER_OPENWRT_WORKSPACE }}:${{ env.CONTAINER_BUILD_AREA }}" \
          -v "${{ github.workspace }}/${{ env.CONTAINER_REPO_CONFIG_MOUNT }}:${{ env.CONTAINER_REPO_CONFIG_MOUNT }}:ro" \
          -e REPO_URL_ENV="${{ env.REPO_URL }}" \
          -e REPO_BRANCH_ENV="${{ env.REPO_BRANCH }}" \
          -e FEEDS_CONF_URL_ENV="${{ env.FEEDS_CONF_URL }}" \
          -e CONFIG_FILE_NAME_IN_REPO="${{ env.CONFIG_FILE_NAME }}" \
          -e DIY_P1_SH_NAME_IN_REPO="${{ env.DIY_P1_SH_NAME }}" \
          -e DIY_P2_SH_NAME_IN_REPO="${{ env.DIY_P2_SH_NAME }}" \
          -e BUILD_STATE_DIR_NAME="${{ env.BUILD_STATE_DIR_NAME }}" \
          -e CCACHE_DIR_NAME="${{ env.CCACHE_DIR_NAME }}" \
          -e CONTAINER_DEBUG_LOG_PATH="${{ env.CONTAINER_DEBUG_LOG_PATH }}" \
          -e CONTAINER_CCACHE_LOG_PATH="${{ env.CONTAINER_CCACHE_LOG_PATH }}" \
          -e CONTAINER_BUILD_AREA="${{ env.CONTAINER_BUILD_AREA }}" \
          -e CONTAINER_REPO_CONFIG_PATH="${{ env.CONTAINER_REPO_CONFIG_MOUNT }}" \
          -e CLEAN_BUILD_FROM_OUTSIDE="${{ github.event.inputs.clean_build }}" \
          -e S3_CACHE_RESTORED_FROM_OUTSIDE="${{ env.S3_CACHE_RESTORED || 'false' }}" \
          -e FEEDS_CHANGED_FROM_OUTSIDE="${{ env.feeds_changed || 'true' }}" \
          -e BUILD_TZ="${{ env.TZ }}" \
          ${{ env.DOCKER_IMAGE }} \
          bash -c "cd ${{ env.CONTAINER_BUILD_AREA }} && /tmp/docker_build_script.sh"
        
        # Check for success/failure marker from Docker script
        if [ -f "${{ env.RUNNER_OPENWRT_WORKSPACE }}/tmp/docker_build_success" ]; then # Path needs to be accessible by runner
            echo "Docker build reported success."
            echo "status=success" >> $GITHUB_OUTPUT
        else
            echo "Docker build reported failure or marker not found."
            echo "status=failure" >> $GITHUB_OUTPUT
            # Optionally copy out logs from mounted repo_config again if they weren't uploaded by Docker directly
            echo "Copying out logs from Docker mapped repo config (if any)..."
            cp "${{ github.workspace }}/${{ env.CONTAINER_REPO_CONFIG_MOUNT }}/docker_build_debug_summary.log" /tmp/docker_build_debug_summary.log 2>/dev/null || true
            cp "${{ github.workspace }}/${{ env.CONTAINER_REPO_CONFIG_MOUNT }}/docker_ccache_detailed.log" /tmp/docker_ccache_detailed.log 2>/dev/null || true
            cp "${{ github.workspace }}/${{ env.CONTAINER_REPO_CONFIG_MOUNT }}/docker_compile_output.log" /tmp/docker_compile_output.log 2>/dev/null || true
            # exit 1 # Fail the step
        fi

    - name: æ‰“åŒ…å¹¶ä¸Šä¼ S3æ„å»ºç¯å¢ƒç¼“å­˜ (Pack & Upload S3 Build Environment Cache)
      if: steps.compile_in_docker.outputs.status == 'success' && !cancelled()
      env:
          S3_BUCKET_NAME_SECRET: ${{ secrets.AWS_S3_BUCKET_NAME }}
          S3_ARCHIVE_NAME_ENV: ${{ env.S3_WORKSPACE_ARCHIVE_FILENAME }}
          RUNNER_WORKSPACE_PATH_ENV: ${{ env.RUNNER_OPENWRT_WORKSPACE }} # This is the dir to pack
          S3_CONFIG_SNAPSHOT_FILENAME_ENV: ${{ env.S3_CONFIG_SNAPSHOT_FILENAME }}
          DEBUG_LOG_FILE: ${{ env.DEBUG_LOG_ON_RUNNER }}
      run: |
        echo "S3_EFFECTIVE_PATH_PREFIX in upload step: ${{ env.S3_EFFECTIVE_PATH_PREFIX }}" | tee -a $DEBUG_LOG_FILE
        if [ -z "$S3_BUCKET_NAME_SECRET" ]; then
          echo "[ERROR] AWS_S3_BUCKET_NAME secret æœªè®¾ç½®ã€‚æ— æ³•ä¸Šä¼ ç¼“å­˜åˆ°S3ã€‚" | tee -a $DEBUG_LOG_FILE
          exit 1 
        fi
        
        echo "å¼€å§‹æ‰“åŒ…å‹ç¼©æ•´ä¸ªå·¥ä½œåŒº: ${RUNNER_WORKSPACE_PATH_ENV} ä¸º /tmp/${S3_ARCHIVE_NAME_ENV} ..." | tee -a $DEBUG_LOG_FILE
        # Tar from the parent of RUNNER_WORKSPACE_PATH_ENV to get the top-level directory name in the archive
        PARENT_DIR_OF_WORKSPACE=$(dirname "${RUNNER_WORKSPACE_PATH_ENV}")
        BASENAME_OF_WORKSPACE=$(basename "${RUNNER_WORKSPACE_PATH_ENV}")

        if tar -I "zstd -T0 -3" -cf "/tmp/${S3_ARCHIVE_NAME_ENV}" -C "${PARENT_DIR_OF_WORKSPACE}" "${BASENAME_OF_WORKSPACE}"; then
          ARCHIVE_SIZE=$(du -sh "/tmp/${S3_ARCHIVE_NAME_ENV}" | awk '{print $1}')
          echo "æ‰“åŒ…å‹ç¼© /tmp/${S3_ARCHIVE_NAME_ENV} æˆåŠŸ. æ–‡ä»¶å¤§å°: $ARCHIVE_SIZE" | tee -a $DEBUG_LOG_FILE
          
          S3_OBJECT_KEY="${{ env.S3_EFFECTIVE_PATH_PREFIX }}/${S3_ARCHIVE_NAME_ENV}"
          echo "å¼€å§‹ä¸Šä¼  /tmp/${S3_ARCHIVE_NAME_ENV} åˆ° s3://${S3_BUCKET_NAME_SECRET}/${S3_OBJECT_KEY} ..." | tee -a $DEBUG_LOG_FILE
          if aws s3 cp "/tmp/${S3_ARCHIVE_NAME_ENV}" "s3://${S3_BUCKET_NAME_SECRET}/${S3_OBJECT_KEY}" --quiet; then
            echo "ä¸Šä¼  /tmp/${S3_ARCHIVE_NAME_ENV} åˆ° S3 æˆåŠŸã€‚" | tee -a $DEBUG_LOG_FILE
          else
            echo "é”™è¯¯ï¼šä¸Šä¼  /tmp/${S3_ARCHIVE_NAME_ENV} åˆ° S3 å¤±è´¥ã€‚" | tee -a $DEBUG_LOG_FILE
          fi
          rm -f "/tmp/${S3_ARCHIVE_NAME_ENV}"
        else
          echo "é”™è¯¯ï¼šæ‰“åŒ…å‹ç¼© ${RUNNER_WORKSPACE_PATH_ENV} å¤±è´¥ã€‚" | tee -a $DEBUG_LOG_FILE
        fi

        # Upload .config from the workspace (it should have been updated by Docker)
        CONFIG_FILE_IN_WORKSPACE="${RUNNER_WORKSPACE_PATH_ENV}/.config"
        if [ -f "$CONFIG_FILE_IN_WORKSPACE" ]; then 
          echo "ä¸Šä¼  .config æ–‡ä»¶ (${CONFIG_FILE_IN_WORKSPACE}) åˆ° S3..." | tee -a $DEBUG_LOG_FILE
          S3_CONFIG_OBJECT_KEY="${{ env.S3_EFFECTIVE_PATH_PREFIX }}/${S3_CONFIG_SNAPSHOT_FILENAME_ENV}"
          if aws s3 cp "$CONFIG_FILE_IN_WORKSPACE" "s3://${S3_BUCKET_NAME_SECRET}/${S3_CONFIG_OBJECT_KEY}" --quiet; then
            echo ".config æ–‡ä»¶æˆåŠŸä¸Šä¼ åˆ° s3://${S3_BUCKET_NAME_SECRET}/${S3_CONFIG_OBJECT_KEY}" | tee -a $DEBUG_LOG_FILE
          else
            echo "é”™è¯¯ï¼šä¸Šä¼  .config æ–‡ä»¶åˆ° S3 å¤±è´¥ã€‚" | tee -a $DEBUG_LOG_FILE
          fi
        else
          echo "è­¦å‘Šï¼š${CONFIG_FILE_IN_WORKSPACE} æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ— æ³•ä¸Šä¼ åˆ°S3ã€‚" | tee -a $DEBUG_LOG_FILE
        fi
        
    # No more GitHub Actions Cache save steps for build components.
    # The 'cache-xxx' steps above were for RESTORE only (or for ccache/state which might still be useful to keep separate).
    # For full Docker env S3 cache, we might remove all actions/cache except maybe for build_state.
    # For now, I've removed specific save steps. actions/cache will save if keys were missed on restore.

    - name: Upload Debug Logs (from Runner and potentially Docker)
      if: always()
      uses: actions/upload-artifact@main
      with:
        name: build-debug-logs-${{ github.run_id }}
        path: |
          ${{ env.DEBUG_LOG_ON_RUNNER }}
          ${{ env.CONTAINER_REPO_CONFIG_MOUNT }}/docker_build_debug_summary.log
          ${{ env.CONTAINER_REPO_CONFIG_MOUNT }}/docker_ccache_detailed.log
          ${{ env.CONTAINER_REPO_CONFIG_MOUNT }}/docker_compile_output.log
          ${{ env.RUNNER_OPENWRT_WORKSPACE }}/config_diff.txt 
          ${{ env.RUNNER_OPENWRT_WORKSPACE }}/.config 
          ${{ env.RUNNER_OPENWRT_WORKSPACE }}/.config.input 
          ${{ env.RUNNER_OPENWRT_WORKSPACE }}/logs/ # Main make logs from inside Docker
        if-no-files-found: ignore # Some Docker logs might not exist if Docker part fails early
        retention-days: 7

    - name: æ•´ç†æ–‡ä»¶ (Organize Firmware Files)
      id: organize
      if: steps.compile_in_docker.outputs.status == 'success' && env.UPLOAD_FIRMWARE == 'true' && !cancelled()
      # This script now needs to look for firmware in ${{ env.RUNNER_OPENWRT_WORKSPACE }}/bin
      run: |
        echo "å¼€å§‹æ•´ç†å›ºä»¶æ–‡ä»¶ from ${{ env.RUNNER_OPENWRT_WORKSPACE }}/bin ..." | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
        FIRMWARE_COLLECTION_DIR_PATH="" 
        OPENWRT_BUILD_ROOT="${{ env.RUNNER_OPENWRT_WORKSPACE }}" # Root of the OpenWrt build env
        OPENWRT_BIN_DIR="${OPENWRT_BUILD_ROOT}/bin"
        OPENWRT_TARGETS_DIR="${OPENWRT_BIN_DIR}/targets"

        if [ ! -d "${OPENWRT_TARGETS_DIR}" ]; then
          echo "é”™è¯¯ï¼šç¼–è¯‘ç›®æ ‡ç›®å½• ${OPENWRT_TARGETS_DIR} ä¸å­˜åœ¨ã€‚" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
          FIRMWARE_COLLECTION_DIR_PATH="/tmp/empty_firmware_collection_$(date +%N)" 
          mkdir -p "${FIRMWARE_COLLECTION_DIR_PATH}"
          echo "FIRMWARE=${FIRMWARE_COLLECTION_DIR_PATH}" >> $GITHUB_ENV
          echo "status=success" >> $GITHUB_OUTPUT 
          echo "FIRMWARE_ZIP=${FIRMWARE_COLLECTION_DIR_PATH}.zip" >> $GITHUB_ENV 
          zip -r9 "${FIRMWARE_COLLECTION_DIR_PATH}.zip" "${FIRMWARE_COLLECTION_DIR_PATH}" 
          exit 0
        fi

        DEEPEST_TARGET_SUBDIRS=$(find "${OPENWRT_TARGETS_DIR}" -mindepth 2 -maxdepth 2 -type d ! -name "packages" -print)
        if [ -z "${DEEPEST_TARGET_SUBDIRS}" ]; then
            echo "è­¦å‘Šï¼šåœ¨ ${OPENWRT_TARGETS_DIR} ä¸‹æœªæ‰¾åˆ°æ ‡å‡†çš„ç›®æ ‡æ¶æ„å­ç›®å½•ã€‚å°è¯•ç›´æ¥åœ¨ ${OPENWRT_TARGETS_DIR} æœç´¢ã€‚" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
            DEEPEST_TARGET_SUBDIRS="${OPENWRT_TARGETS_DIR}" 
        fi
        
        # Collection dir will be outside the main openwrt workspace to avoid re-packing it into S3
        FINAL_FIRMWARE_OUTPUT_BASE="/tmp/firmware_output_collections"
        mkdir -p $FINAL_FIRMWARE_OUTPUT_BASE

        for CURRENT_IMG_SOURCE_DIR in $DEEPEST_TARGET_SUBDIRS; do
            echo "æ£€æŸ¥ç›®å½•: ${CURRENT_IMG_SOURCE_DIR} ä¸­çš„å›ºä»¶æ–‡ä»¶..." | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
            COLLECTED_FIRMWARE_OUTPUT_DIR="${FINAL_FIRMWARE_OUTPUT_BASE}/firmware_collection_$(basename ${CURRENT_IMG_SOURCE_DIR})_$(date +%N)"
            mkdir -p "${COLLECTED_FIRMWARE_OUTPUT_DIR}"
            FILES_COPIED_COUNT=0
            
            cd "${CURRENT_IMG_SOURCE_DIR}" 
            
            for pattern in "*combined.img.gz" "*sysupgrade.img.gz" "*combined-efi.img.gz" "*kernel.bin" "*.img" "*.bin"; do
                find . -maxdepth 1 -type f -name "$pattern" ! -path "./packages/*" -print0 | while IFS= read -r -d $'\0' found_file; do
                    cp -v -f "${found_file}" "${COLLECTED_FIRMWARE_OUTPUT_DIR}/"
                    FILES_COPIED_COUNT=$((FILES_COPIED_COUNT + 1))
                done
            done
            
            if [ $FILES_COPIED_COUNT -eq 0 ]; then
                echo "åœ¨ ${CURRENT_IMG_SOURCE_DIR} ä¸­æœªæ‰¾åˆ°æ ‡å‡†æ¨¡å¼çš„å›ºä»¶ï¼Œå°è¯•å¤åˆ¶å…¶ä»–å¯èƒ½çš„æ–‡ä»¶..." | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
                find . -maxdepth 1 -type f \
                  ! -name "*.manifest" ! -name "*.txt" ! -name "*.json" ! -name "*.buildinfo" ! -name "sha256sums" \
                  ! -path "./packages/*" \
                  -print0 | while IFS= read -r -d $'\0' found_file; do
                    cp -v -f "${found_file}" "${COLLECTED_FIRMWARE_OUTPUT_DIR}/"
                    FILES_COPIED_COUNT=$((FILES_COPIED_COUNT + 1))
                done
            fi
            # Go back to a known neutral directory or runner's workdir to avoid issues with subsequent cd
            cd "${{ github.workspace }}/${{ env.CONTAINER_REPO_CONFIG_MOUNT }}" 


            if [ $FILES_COPIED_COUNT -gt 0 ]; then
                echo "æˆåŠŸä» ${CURRENT_IMG_SOURCE_DIR} å¤åˆ¶ $FILES_COPIED_COUNT ä¸ªæ–‡ä»¶åˆ° ${COLLECTED_FIRMWARE_OUTPUT_DIR}" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
                if [ -f "${OPENWRT_BUILD_ROOT}/.config" ]; then # .config from the build environment
                  cp -v -f "${OPENWRT_BUILD_ROOT}/.config" "${COLLECTED_FIRMWARE_OUTPUT_DIR}/config.txt"
                fi
                ls -lh "${COLLECTED_FIRMWARE_OUTPUT_DIR}" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
                FIRMWARE_COLLECTION_DIR_PATH="${COLLECTED_FIRMWARE_OUTPUT_DIR}" 
                break 
            else
                echo "è­¦å‘Š: åœ¨ ${CURRENT_IMG_SOURCE_DIR} ä¸­æœªæ‰¾åˆ°å¯ç”¨å›ºä»¶æ–‡ä»¶å¯æ”¶é›†ã€‚" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
                rm -rf "${COLLECTED_FIRMWARE_OUTPUT_DIR}" 
            fi
        done

        if [ -z "${FIRMWARE_COLLECTION_DIR_PATH}" ]; then
            echo "è­¦å‘Šï¼šæœªèƒ½åœ¨ä»»ä½•æ ‡å‡†ç›®æ ‡å­ç›®å½•ä¸­æ”¶é›†åˆ°å›ºä»¶æ–‡ä»¶ã€‚å¯ç”¨ç´§æ€¥å¤‡ç”¨æ”¶é›†é€»è¾‘ã€‚" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
            FIRMWARE_COLLECTION_DIR_PATH="${FINAL_FIRMWARE_OUTPUT_BASE}/firmware_fallback_collection_$(date +%N)"
            mkdir -p "${FIRMWARE_COLLECTION_DIR_PATH}"
            find "${OPENWRT_TARGETS_DIR}" -type f \( -name "*.bin" -o -name "*.img" -o -name "*.img.gz" \) ! -path "*/packages/*" ! -path "*/firmware_collection_*" -exec cp -v -f {} "${FIRMWARE_COLLECTION_DIR_PATH}/" \;
            if [ -f "${OPENWRT_BUILD_ROOT}/.config" ]; then 
                cp -v -f "${OPENWRT_BUILD_ROOT}/.config" "${FIRMWARE_COLLECTION_DIR_PATH}/config.txt";
            else 
                echo "# Fallback .config - actual .config not found" > "${FIRMWARE_COLLECTION_DIR_PATH}/config.txt"; 
            fi
        fi

        echo "FIRMWARE=${FIRMWARE_COLLECTION_DIR_PATH}" >> $GITHUB_ENV
        echo "status=success" >> $GITHUB_OUTPUT

        if [ -n "${FIRMWARE_COLLECTION_DIR_PATH}" ] && [ -d "${FIRMWARE_COLLECTION_DIR_PATH}" ] && [ "$(ls -A "${FIRMWARE_COLLECTION_DIR_PATH}")" ]; then
            FIRMWARE_PARENT_DIR=$(dirname "${FIRMWARE_COLLECTION_DIR_PATH}")
            FIRMWARE_BASENAME=$(basename "${FIRMWARE_COLLECTION_DIR_PATH}")
            ZIP_FILENAME="${FIRMWARE_BASENAME}.zip" 
            
            echo "åˆ›å»ºå›ºä»¶å‹ç¼©åŒ… ${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME} ä»ç›®å½• ${FIRMWARE_BASENAME}" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
            cd "${FIRMWARE_PARENT_DIR}" && zip -r9 "${ZIP_FILENAME}" "${FIRMWARE_BASENAME}"
            
            if [ -f "${ZIP_FILENAME}" ]; then
                echo "FIRMWARE_ZIP=${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME}" >> $GITHUB_ENV
                ls -lh "${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME}" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
            else
                echo "é”™è¯¯ï¼šå‹ç¼©åŒ… ${ZIP_FILENAME} æœªèƒ½æˆåŠŸåˆ›å»ºã€‚" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
                echo "FIRMWARE_ZIP=/tmp/zip_creation_failed_$(date +%N).zip" >> $GITHUB_ENV 
            fi
        else
            echo "è­¦å‘Š: æœ€ç»ˆå›ºä»¶æ”¶é›†ç›®å½• (${FIRMWARE_COLLECTION_DIR_PATH}) æœªæœ‰æ•ˆè®¾ç½®ã€ä¸æ˜¯ç›®å½•æˆ–ä¸ºç©ºï¼Œæ— æ³•åˆ›å»º firmware.zipã€‚" | tee -a ${{ env.DEBUG_LOG_ON_RUNNER }}
            echo "FIRMWARE_ZIP=/tmp/no_firmware_to_zip_$(date +%N).zip" >> $GITHUB_ENV
        fi

    - name: ä¸Šä¼ å›ºä»¶ (Artifact)
      uses: actions/upload-artifact@main
      if: steps.organize.outputs.status == 'success' && env.UPLOAD_FIRMWARE == 'true' && !cancelled()
      with:
        name: OpenWrt_firmware${{ env.DEVICE_NAME }}${{ env.FILE_DATE }}
        path: ${{ env.FIRMWARE_ZIP }} 
        if-no-files-found: warn

    - name: ç”Ÿæˆå‘å¸ƒæ ‡ç­¾ (Generate Release Tag)
      id: tag
      if: steps.organize.outputs.status == 'success' && env.UPLOAD_RELEASE == 'true' && !cancelled()
      run: |
        # (Script content remains the same as in 'å…¨æ–°ç¼–è¯‘ç¬¬14.1ç‰ˆ')
        RELEASE_TAG_BASE=$(date +"%Y.%m.%d-%H%M")
        DEVICE_TAG_PART=$(echo "${{ env.DEVICE_NAME }}" | sed 's/^_//;s/_$//' | sed 's/[^a-zA-Z0-9._-]/-/g' )
        if [ -n "$DEVICE_TAG_PART" ] && [ "$DEVICE_TAG_PART" != "-" ]; then FINAL_RELEASE_TAG="${RELEASE_TAG_BASE}_${DEVICE_TAG_PART}"; else FINAL_RELEASE_TAG="${RELEASE_TAG_BASE}"; fi
        echo "RELEASE_TAG=${FINAL_RELEASE_TAG}" >> $GITHUB_OUTPUT
        echo "## OpenWrt Firmware Build ($(date +"%Y-%m-%d %H:%M %Z")) ğŸ“¦" > release_body.txt
        echo "" >> release_body.txt
        echo "**Branch:** \`${{ env.REPO_BRANCH }}\`" >> release_body.txt
        echo "**Config:** \`${{ env.CONFIG_FILE_NAME }}\`" >> release_body.txt
        if [ -n "$DEVICE_TAG_PART" ] && [ "$DEVICE_TAG_PART" != "-" ]; then echo "**Device:** \`${{ env.DEVICE_NAME }}\`" >> release_body.txt; fi
        echo "" >> release_body.txt
        echo "### å›ºä»¶ä¸‹è½½ (Firmware Download)" >> release_body.txt
        echo "è¯·åœ¨ä¸‹æ–¹ Assets ä¸­æ‰¾åˆ°å›ºä»¶æ–‡ä»¶ (é€šå¸¸æ˜¯ä¸€ä¸ª .zip å‹ç¼©åŒ…)ã€‚" >> release_body.txt
        echo "Please find firmware files (usually a .zip archive) in the Assets section below." >> release_body.txt
        echo "" >> release_body.txt; echo "---" >> release_body.txt
        echo "âš ï¸ **åˆ·æœºå‰è¯·åŠ¡å¿…å¤‡ä»½é‡è¦æ•°æ®ï¼**" >> release_body.txt
        echo "âš ï¸ **Backup your important data before flashing!**" >> release_body.txt
        echo "" >> release_body.txt
        echo "_Built by GitHub Actions - Workflow: [${{ github.workflow }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})_" >> release_body.txt
        echo "status=success" >> $GITHUB_OUTPUT


    - name: ä¸Šä¼ å›ºä»¶åˆ°Releases (Upload Firmware to Releases)
      uses: softprops/action-gh-release@v2
      if: steps.tag.outputs.status == 'success' && !cancelled()
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ steps.tag.outputs.RELEASE_TAG }}
        body_path: release_body.txt
        files: ${{ env.FIRMWARE_ZIP }} 

    - name: åˆ é™¤æ—§çš„Releases (Delete Old Releases)
      uses: dev-drprasad/delete-older-releases@master
      if: env.UPLOAD_RELEASE == 'true' && !cancelled()
      with:
        keep_latest: 3
        delete_tags: true
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
