name: å…¨æ–°ç¼–è¯‘ç¬¬14ç‰ˆ(Docker-Så…¨ç¼“å­˜-å¢å¼ºè¯Šæ–­ç‰ˆ)

on:
  workflow_dispatch:
    inputs:
      ssh:
        description: 'SSHè°ƒè¯• (åœ¨Dockerå®¹å™¨å†…éƒ¨)'
        required: false
        default: 'false'
      clean_build:
        description: 'å…¨æ–°ç¼–è¯‘ï¼Œä¸ä½¿ç”¨S3æ¢å¤çš„ç¯å¢ƒã€‚ä»ä¼šæ‰“åŒ…ä¸Šä¼ æ–°ç¯å¢ƒåˆ°S3ã€‚é¦–æ¬¡S3å¡«å……æ—¶åº”ä¸ºfalseå¹¶é¢„æ¸…ç©ºS3ã€‚'
        required: false
        default: 'false'

env:
  REPO_URL: https://github.com/coolsnowwolf/lede
  REPO_BRANCH: master
  FEEDS_CONF_URL: https://github.com/tikkacn/openwrt-new-rom/raw/main/feeds.conf.default
  CONFIG_FILE_IN_REPO: å¢é‡ç¼“å­˜ä¼˜åŒ–.config
  DIY_P1_SH_IN_REPO: diy-part1.sh
  DIY_P2_SH_IN_REPO: diy-part2.sh
  UPLOAD_FIRMWARE: true
  UPLOAD_RELEASE: true
  TZ: Asia/Shanghai

  RUNNER_CHECKOUT_SUBDIR: 'repo_files'
  CONTAINER_REPO_CONFIG_MOUNT: /repo_config
  DOCKER_IMAGE: ubuntu:22.04

  S3_DL_DIR_ARCHIVE_BASENAME: openwrt_dl_cache.tar.zst
  S3_STAGING_DIR_ARCHIVE_BASENAME: openwrt_staging_dir_cache.tar.zst
  S3_BUILD_DIR_HOST_ARCHIVE_BASENAME: openwrt_build_dir_host_cache.tar.zst
  S3_BUILD_DIR_TOOLCHAIN_ARCHIVE_BASENAME: openwrt_build_dir_toolchain_cache.tar.zst
  S3_BUILD_DIR_TARGET_ARCHIVE_BASENAME: openwrt_build_dir_target.tar.zst
  S3_FEEDS_CACHE_ARCHIVE_BASENAME: openwrt_feeds_cache.tar.zst
  S3_CCACHE_ARCHIVE_BASENAME: openwrt_ccache.tar.zst
  S3_BUILD_STATE_ARCHIVE_BASENAME: openwrt_build_state.tar.zst
  S3_DOT_CONFIG_FILENAME: dot_config_snapshot

  CONTAINER_DL_DIR_RELPATH: "dl"
  CONTAINER_STAGING_DIR_RELPATH: "staging_dir"
  CONTAINER_BUILD_DIR_HOST_RELPATH: "build_dir/host"
  CONTAINER_FEEDS_DIR_RELPATH: "feeds"
  CONTAINER_CCACHE_DIR_RELPATH: ".ccache"
  CONTAINER_BUILD_STATE_DIR_RELPATH: ".github_actions_build_state"

  CONTAINER_CCACHE_LOGFILE_PATH: /tmp/ccache_detailed.log
  CONTAINER_DEBUG_LOG_FILE_PATH: /tmp/build_debug_summary.log

  RUNNER_OPENWRT_WORKSPACE: /workdir/openwrt_s3_env
  CONTAINER_BUILD_AREA: /workdir/openwrt_s3_env

  CF_CDN_DOMAIN: https://d16xdi3lv2va77.cloudfront.net

jobs:
  build_in_docker:
    runs-on: ubuntu-22.04
    name: Build OpenWrt in Docker with S3 Chunked Env Cache
    env:
      RUNNER_OPENWRT_WORKSPACE: /workdir/openwrt_s3_env
      CONTAINER_BUILD_AREA: /workdir/openwrt_s3_env
    steps:
      - name: æ£€å‡ºä»“åº“ä»£ç  (Checkout Repository Code)
        uses: actions/checkout@v4
        with:
          path: ${{ env.RUNNER_CHECKOUT_SUBDIR }}

      - name: è®¾ç½® S3/CloudFront ç¼“å­˜å®Œæ•´è·¯å¾„å‰ç¼€ (Set Full S3/CF Cache Path Prefix)
        id: set_s3_vars
        run: |
          s3_prefix_from_secret="${{ secrets.S3_CACHE_PATH_PREFIX }}"
          repo_branch_for_path="${{ env.REPO_BRANCH }}"
          repo_branch_for_path_sanitized=$(echo "$repo_branch_for_path" | sed 's/\//-/g')
          final_s3_prefix=""
          if [ -n "$s3_prefix_from_secret" ]; then
            final_s3_prefix="$s3_prefix_from_secret"
          else
            default_prefix="openwrt-s3chunks-v3/${repo_branch_for_path_sanitized}"
            final_s3_prefix="$default_prefix"
          fi
          echo "S3_EFFECTIVE_PATH_PREFIX=${final_s3_prefix}" >> $GITHUB_ENV
          echo "CF_EFFECTIVE_URL_PREFIX=${{ env.CF_CDN_DOMAIN }}/${final_s3_prefix}" >> $GITHUB_ENV
          echo "s3_prefix_out=${final_s3_prefix}" >> $GITHUB_OUTPUT
          echo "DEBUG_LOG_ON_RUNNER=${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}/build_debug_summary_runner.log" >> $GITHUB_ENV

      - name: ä¼˜åŒ–Runnerç£ç›˜ç©ºé—´ (Maximize Runner Build Space)
        uses: easimon/maximize-build-space@master
        with:
          root-reserve-mb: 20480
          swap-size-mb: 4096
          remove-dotnet: 'true'
          remove-android: 'true'
          remove-haskell: 'true'
          remove-codeql: 'true'
          remove-docker-images: 'false'
          build-mount-path: '/workdir'

      - name: é…ç½® AWS å‡­è¯ (Configure AWS Credentials)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: CloudFront CDN ç¼“å­˜è¿˜åŸä¸å…³é”®ç›®å½•æ£€æŸ¥ (Restore Cache from CloudFront CDN)
        if: inputs.clean_build != 'true'
        env:
          CF_EFFECTIVE_URL_PREFIX: ${{ env.CF_EFFECTIVE_URL_PREFIX }}
          DEBUG_LOG_FILE: ${{ env.DEBUG_LOG_ON_RUNNER }}
        run: |
          set -e
          echo "==========[TIMESTAMP][CloudFrontç¼“å­˜è¿˜åŸå‰] $(date '+%F %T')=========="
          echo "CF_EFFECTIVE_URL_PREFIX in download step: $CF_EFFECTIVE_URL_PREFIX" | tee -a "$DEBUG_LOG_FILE"
          RESTORE_TMP=/workdir/openwrt_s3cache_restore_tmp
          mkdir -p "$RESTORE_TMP"

          cf_download_and_extract_parts() {
            local archive_basename="$1"
            local target_extract_path="$2"
            local chunk_restore_tmp_dir="/tmp/cf_restore_chunks_$(echo "$archive_basename" | tr -dc 'a-zA-Z0-9_')"
            mkdir -p "${chunk_restore_tmp_dir}"
            local manifest_url="${CF_EFFECTIVE_URL_PREFIX}/${archive_basename}.manifest"
            local local_manifest_file="${chunk_restore_tmp_dir}/${archive_basename}.manifest"
            if curl -fsSL --retry 3 -o "${local_manifest_file}" "${manifest_url}"; then
              mapfile -t chunk_files_to_download < "${local_manifest_file}"
              if [ ${#chunk_files_to_download[@]} -eq 0 ]; then rm -rf "${chunk_restore_tmp_dir}"; return; fi
              local all_chunks_downloaded=true; declare -a downloaded_chunk_paths_ordered
              for chunk_filename_dirty in "${chunk_files_to_download[@]}"; do
                local chunk_filename=$(echo "$chunk_filename_dirty" | tr -d '\r\n'); [ -z "$chunk_filename" ] && continue
                local chunk_url="${CF_EFFECTIVE_URL_PREFIX}/${chunk_filename}"; local local_chunk_path="${chunk_restore_tmp_dir}/${chunk_filename}"
                if ! curl -fSL --retry 3 -o "${local_chunk_path}" "${chunk_url}"; then all_chunks_downloaded=false; fi
                downloaded_chunk_paths_ordered+=("${local_chunk_path}")
              done
              if [ "$all_chunks_downloaded" = true ] && [ ${#downloaded_chunk_paths_ordered[@]} -gt 0 ]; then
                cat ${downloaded_chunk_paths_ordered[@]} | zstd -d -T0 - | tar -xf - -C "${target_extract_path}"
              fi
            else
              local single_archive_url="${CF_EFFECTIVE_URL_PREFIX}/${archive_basename}"
              local single_local_archive="${chunk_restore_tmp_dir}/${archive_basename}"
              if curl -fSL --retry 3 -o "${single_local_archive}" "${single_archive_url}"; then
                tar -I "zstd -T0" -xf "${single_local_archive}" -C "${target_extract_path}"
              fi
            fi
            rm -rf "${chunk_restore_tmp_dir}"
          }
          cf_download_and_extract_parts "${{ env.S3_DL_DIR_ARCHIVE_BASENAME }}" "$RESTORE_TMP"
          cf_download_and_extract_parts "${{ env.S3_STAGING_DIR_ARCHIVE_BASENAME }}" "$RESTORE_TMP"
          cf_download_and_extract_parts "${{ env.S3_BUILD_DIR_HOST_ARCHIVE_BASENAME }}" "$RESTORE_TMP"
          cf_download_and_extract_parts "${{ env.S3_BUILD_DIR_TOOLCHAIN_ARCHIVE_BASENAME }}" "$RESTORE_TMP"
          cf_download_and_extract_parts "${{ env.S3_BUILD_DIR_TARGET_ARCHIVE_BASENAME }}" "$RESTORE_TMP"
          cf_download_and_extract_parts "${{ env.S3_FEEDS_CACHE_ARCHIVE_BASENAME }}" "$RESTORE_TMP"
          cf_download_and_extract_parts "${{ env.S3_CCACHE_ARCHIVE_BASENAME }}" "$RESTORE_TMP"
          cf_download_and_extract_parts "${{ env.S3_BUILD_STATE_ARCHIVE_BASENAME }}" "$RESTORE_TMP"
          echo "S3_CACHE_RESTORE_ATTEMPTED=true" >> $GITHUB_ENV

          echo "==========[TIMESTAMP][CloudFrontç¼“å­˜è¿˜åŸå] $(date '+%F %T')=========="
          echo "CDNç¼“å­˜ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š"
          find $RESTORE_TMP | head -100
          for d in dl staging_dir build_dir .ccache; do
            path="$RESTORE_TMP/$d"
            if [ ! -d "$path" ] || [ -z "$(ls -A $path 2>/dev/null)" ]; then
              echo "::error file=$0,line=$LINENO::[CDNç¼“å­˜ç›®å½• $d æœªæˆåŠŸæ¢å¤æˆ–ä¸ºç©º!]"
              exit 2
            else
              echo "[OK] CDNç¼“å­˜ç›®å½• $d å­˜åœ¨ä¸”éç©ºã€‚"
              du -sh "$path"
            fi
          done
          find $RESTORE_TMP -type f -name '*.tar.zst*' -exec ls -lh {} \;

      - name: æ£€æŸ¥ CDN ç¼“å­˜è¿˜åŸç»“æœï¼ˆä¸´æ—¶ç›®å½•ï¼‰
        run: |
          RESTORE_TMP=/workdir/openwrt_s3cache_restore_tmp
          echo "Restored CDN cache content:"
          find $RESTORE_TMP

      - name: è¿è¡ŒDockerå®¹å™¨å¹¶æ‰§è¡Œç¼–è¯‘ (Run Docker Container & Compile)
        id: compile_in_docker
        env:
          S3_CACHE_RESTORE_ATTEMPTED: ${{ env.S3_CACHE_RESTORE_ATTEMPTED }}
        run: |
          RUNNER_SCRIPT_FILENAME="docker_build_script.sh"
          RUNNER_SCRIPT_PATH="${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}/${RUNNER_SCRIPT_FILENAME}"
          CONTAINER_SCRIPT_PATH="${{ env.CONTAINER_REPO_CONFIG_MOUNT }}/${RUNNER_SCRIPT_FILENAME}"
          cat << 'DOCKER_SCRIPT_EOF' > "${RUNNER_SCRIPT_PATH}"
          #!/bin/bash
          set -eo pipefail

          # === è¯Šæ–­æ—¥å¿—æ”¶é›†åˆå§‹åŒ–ï¼ˆä¿®æ­£ç‰ˆï¼Œå…ˆç¡®ä¿ç›®å½•å­˜åœ¨ï¼‰ ===
          DIAG_DIR="bin/targets/__diagnose"
          DIAG_FILE="$DIAG_DIR/diagnose_summary.txt"
          mkdir -p "$DIAG_DIR"
          : > "$DIAG_FILE"
          add_diag() { echo -e "$1" | tee -a "$DIAG_FILE"; }

          export FORCE_UNSAFE_CONFIGURE=1
          export GOFLAGS="-buildvcs=false"
          INTERNAL_DEBUG_LOG="${DOCKER_ENV_CONTAINER_DEBUG_LOG_PATH:-/tmp/container_build_debug.log}"
          mkdir -p "$(dirname "${INTERNAL_DEBUG_LOG}")"
          echo "[DOCKER] Starting build script..." | tee -a "${INTERNAL_DEBUG_LOG}"

          apt-get update -y && apt-get install -y --no-install-recommends \
            ca-certificates git build-essential libncurses5-dev libncursesw5-dev zlib1g-dev libssl-dev \
            subversion gawk wget curl python3 python3-distutils unzip file patch rsync util-linux procps \
            ccache libelf-dev libfuse-dev libglib2.0-dev libgmp3-dev libltdl-dev libmpc-dev libmpfr-dev \
            libreadline-dev libtool llvm p7zip p7zip-full xsltproc xxd gettext autopoint time
          apt-get clean && rm -rf /var/lib/apt/lists/*
          export TZ="${DOCKER_ENV_BUILD_TZ:-Asia/Shanghai}"
          ln -snf "/usr/share/zoneinfo/$TZ" /etc/localtime && echo "$TZ" > /etc/timezone

          cd "${DOCKER_ENV_CONTAINER_BUILD_AREA}"
          rm -rf ./* .[^.]* .??* 2>/dev/null || true
          echo "[DOCKER] Directory cleaned for git clone. Contents now:"
          ls -al

          echo "[DOCKER] Cloning OpenWrt into '.' ..."
          git clone --depth 1 "${DOCKER_ENV_REPO_URL}" -b "${DOCKER_ENV_REPO_BRANCH}" .
          if [ $? -ne 0 ]; then add_diag "[DOCKER_ERROR] git clone failed!"; exit 1; fi
          echo "[INFO] Removing .git directory after clone..."; rm -rf .git

          if [ -d "/restore_tmp" ]; then
            echo "[DOCKER] Restoring S3 cache directories from /restore_tmp ..."
            for d in .github_actions_build_state .ccache build_dir dl feeds staging_dir; do
              if [ -d "/restore_tmp/\$d" ]; then
                echo "[DOCKER] Restoring \$d ..."
                rm -rf "./\$d"
                cp -a "/restore_tmp/\$d" "./"
              fi
            done
          fi

          INTERNAL_BUILD_STATE_DIR_NAME_ACTUAL=".github_actions_build_state"
          INTERNAL_CCACHE_DIR_NAME_ACTUAL="${DOCKER_ENV_CCACHE_DIR_NAME:-.ccache}"
          mkdir -p "./${INTERNAL_BUILD_STATE_DIR_NAME_ACTUAL}" "./${INTERNAL_CCACHE_DIR_NAME_ACTUAL}" "./logs"
          export CCACHE_DIR="${PWD}/${INTERNAL_CCACHE_DIR_NAME_ACTUAL}"
          export CCACHE_LOGFILE="${DOCKER_ENV_CONTAINER_CCACHE_LOG_PATH:-/tmp/container_ccache_detailed.log}"
          mkdir -p "$(dirname "${CCACHE_LOGFILE}")"; ccache -M 8G; ccache -z

          INTERNAL_CONFIG_FILE_NAME="${DOCKER_ENV_CONFIG_FILE_NAME_IN_REPO:-å¢é‡ç¼“å­˜ä¼˜åŒ–.config}"
          INTERNAL_DIY_P1_SH_NAME="${DOCKER_ENV_DIY_P1_SH_NAME_IN_REPO:-diy-part1.sh}"
          INTERNAL_DIY_P2_SH_NAME="${DOCKER_ENV_DIY_P2_SH_NAME_IN_REPO:-diy-part2.sh}"

          cp "${DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH}/${INTERNAL_CONFIG_FILE_NAME}" "./.config"
          cp ./.config ./.config.input
          cp "${DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH}/${INTERNAL_DIY_P1_SH_NAME}" "./${INTERNAL_DIY_P1_SH_NAME}" && chmod +x "./${INTERNAL_DIY_P1_SH_NAME}"
          cp "${DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH}/${INTERNAL_DIY_P2_SH_NAME}" "./${INTERNAL_DIY_P2_SH_NAME}" && chmod +x "./${INTERNAL_DIY_P2_SH_NAME}"

          "./${INTERNAL_DIY_P1_SH_NAME}"

          if [ -f "${DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH}/feeds.conf.default" ]; then cp "${DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH}/feeds.conf.default" "./feeds.conf.default"; elif [ ! -f "./feeds.conf.default" ] && [ -f "./feeds.conf.default.sample" ]; then cp feeds.conf.default.sample feeds.conf.default; fi
          ./scripts/feeds update -a; ./scripts/feeds install -a; "./${INTERNAL_DIY_P2_SH_NAME}"

          echo "CONFIG_AUTOREMOVE=y" >> .config; echo "CONFIG_AUTOREBUILD=y" >> .config
          if ! grep -q "CONFIG_TARGET_ROOTFS_SQUASHFS=y" .config; then echo "CONFIG_TARGET_ROOTFS_SQUASHFS=y" >> .config; fi
          if ! grep -q "CONFIG_TARGET_IMAGES_GZIP=y" .config; then echo "CONFIG_TARGET_IMAGES_GZIP=y" >> .config; fi

          make defconfig

          TOOLCHAIN_CONFIG_SUBSET_FOR_MD5=$(grep -E "^CONFIG_TARGET|^CONFIG_ARCH|^CONFIG_TOOLCHAIN" .config | grep -v "NOT_SET" | sort)
          TOOLCHAIN_MD5=$(echo "$TOOLCHAIN_CONFIG_SUBSET_FOR_MD5" | md5sum | awk '{print $1}')
          PREVIOUS_TOOLCHAIN_MD5=$(cat "./.github_actions_build_state/toolchain.md5" 2>/dev/null || echo "not_found_in_build_state")
          PACKAGE_CONFIG_SUBSET_FOR_MD5=$(grep "^CONFIG_PACKAGE_" .config | grep "=y" | sort)
          PACKAGE_MD5=$(echo "$PACKAGE_CONFIG_SUBSET_FOR_MD5" | md5sum | awk '{print $1}')
          PREVIOUS_PACKAGE_MD5=$(cat "./.github_actions_build_state/package.md5" 2>/dev/null || echo "not_found_in_build_state")

          # === è¯Šæ–­æ—¥å¿—å…³é”®ç‚¹æ”¶é›† ===
          if [ "${DOCKER_ENV_S3_CACHE_RESTORED_FROM_OUTSIDE}" != "true" ]; then
            add_diag "åŸå› ï¼šS3ç¼“å­˜æœªè¿˜åŸï¼Œå¿…é¡»å…¨é‡ç¼–è¯‘ã€‚"
          fi
          if [ "${DOCKER_ENV_CLEAN_BUILD_FROM_OUTSIDE}" = "true" ]; then
            add_diag "åŸå› ï¼šclean_buildè§¦å‘ï¼Œå¼ºåˆ¶å…¨é‡ç¼–è¯‘ã€‚"
          fi
          if [ "$PREVIOUS_TOOLCHAIN_MD5" = "not_found_in_build_state" ]; then
            add_diag "åŸå› ï¼šä¸Šæ¬¡toolchain.md5ç¼ºå¤±ï¼Œæ— æ³•å¢é‡ã€‚"
          elif [ "$TOOLCHAIN_MD5" != "$PREVIOUS_TOOLCHAIN_MD5" ]; then
            add_diag "åŸå› ï¼štoolchain.md5å˜åŠ¨ï¼ˆæœ¬æ¬¡ï¼š$TOOLCHAIN_MD5ï¼Œä¸Šæ¬¡ï¼š$PREVIOUS_TOOLCHAIN_MD5ï¼‰ï¼Œéœ€å…¨é‡ç¼–è¯‘ã€‚"
          fi
          if [ "$PREVIOUS_PACKAGE_MD5" = "not_found_in_build_state" ]; then
            add_diag "åŸå› ï¼šä¸Šæ¬¡package.md5ç¼ºå¤±ï¼Œæ— æ³•å¢é‡ã€‚"
          elif [ "$PACKAGE_MD5" != "$PREVIOUS_PACKAGE_MD5" ]; then
            add_diag "åŸå› ï¼špackage.md5å˜åŠ¨ï¼ˆæœ¬æ¬¡ï¼š$PACKAGE_MD5ï¼Œä¸Šæ¬¡ï¼š$PREVIOUS_PACKAGE_MD5ï¼‰ï¼Œéœ€åŒ…ç¼–è¯‘ã€‚"
          fi
          if [ -f .github_actions_build_state/config_from_compile_step.txt ]; then
            if ! diff .config .github_actions_build_state/config_from_compile_step.txt >/dev/null; then
              add_diag "configå˜åŠ¨:\n$(diff .config .github_actions_build_state/config_from_compile_step.txt | head -20)"
            fi
          fi
          if [ -f feeds.conf.default ] && [ -f .github_actions_build_state/feeds.conf.default ]; then
            if ! diff feeds.conf.default .github_actions_build_state/feeds.conf.default >/dev/null; then
              add_diag "feeds.conf.defaultå˜åŠ¨:\n$(diff feeds.conf.default .github_actions_build_state/feeds.conf.default | head -20)"
            fi
          fi
          CCACHE_STATS=$(ccache -s 2>/dev/null || true)
          CCACHE_HIT=$(echo "$CCACHE_STATS" | grep "hit rate" | awk '{print $3}')
          add_diag "ccacheå‘½ä¸­ç‡: $CCACHE_HIT"
          if [ "$CCACHE_HIT" = "0.0%" ]; then
            add_diag "åŸå› ï¼šccacheæœªå‘½ä¸­ï¼Œå»ºè®®æ£€æŸ¥CCACHE_DIRå’Œä¸»æœºæ—¶é’Ÿ/æ–‡ä»¶æˆ³ã€‚"
          fi

          start_time=$(date +%s)
          MAKE_JOBS_NPROC=$(nproc); MAKE_OPTS_COMMON_GOFLAGS="GOFLAGS=-buildvcs=false"
          MAKE_OPTS_MAIN="-j${MAKE_JOBS_NPROC} V=s ${MAKE_OPTS_COMMON_GOFLAGS}"
          MAKE_OPTS_FALLBACK="-j1 V=s ${MAKE_OPTS_COMMON_GOFLAGS}"
          COMPILE_OUTPUT_LOG_DOCKER="logs/compile_output_docker_$(date +%Y%m%d_%H%M%S).log"
          final_install_status_docker=0
          if [ $DO_FULL_BUILD_DOCKER -eq 1 ]; then
            make tools/compile ${MAKE_OPTS_FALLBACK} || make tools/compile ${MAKE_OPTS_FALLBACK}
            make toolchain/compile ${MAKE_OPTS_FALLBACK} || make toolchain/compile ${MAKE_OPTS_FALLBACK}
            if ! make ${MAKE_OPTS_MAIN} 2>&1 | tee "${COMPILE_OUTPUT_LOG_DOCKER}"; then make ${MAKE_OPTS_FALLBACK} 2>&1 | tee -a "${COMPILE_OUTPUT_LOG_DOCKER}"; fi
          elif [ $DO_PACKAGE_BUILD_DOCKER -eq 1 ]; then
            make package/clean V=s || true
            if ! make package/compile ${MAKE_OPTS_MAIN} 2>&1 | tee "${COMPILE_OUTPUT_LOG_DOCKER}"; then make package/compile ${MAKE_OPTS_FALLBACK} 2>&1 | tee -a "${COMPILE_OUTPUT_LOG_DOCKER}"; fi
            make package/index -j1 || make package/index -j1
          else
            if ! make ${MAKE_OPTS_MAIN} 2>&1 | tee "${COMPILE_OUTPUT_LOG_DOCKER}"; then make ${MAKE_OPTS_FALLBACK} 2>&1 | tee -a "${COMPILE_OUTPUT_LOG_DOCKER}"; fi
          fi
          make target/install ${MAKE_OPTS_FALLBACK} 2>&1 | tee -a "${COMPILE_OUTPUT_LOG_DOCKER}"; final_install_status_docker=$?
          make prepare ${MAKE_OPTS_MAIN} || make prepare ${MAKE_OPTS_FALLBACK}
          make tools/install ${MAKE_OPTS_MAIN} IGNORE_ERRORS=m || make tools/install ${MAKE_OPTS_FALLBACK} IGNORE_ERRORS=m
          make toolchain/install ${MAKE_OPTS_MAIN} IGNORE_ERRORS=m || make toolchain/install ${MAKE_OPTS_FALLBACK} IGNORE_ERRORS=m

          end_time=$(date +%s)
          elapsed=$((end_time - start_time))

          # ç¼–è¯‘å¤±è´¥è¯Šæ–­
          if [ "$final_install_status_docker" != "0" ]; then
            add_diag "åŸå› ï¼šmakeå‡ºé”™ï¼Œè¯¦è§compileæ—¥å¿—ã€‚"
          fi

          add_diag "æœ¬æ¬¡makeè€—æ—¶: ${elapsed}ç§’"

          mkdir -p "./${INTERNAL_BUILD_STATE_DIR_NAME_ACTUAL}"; cp .config "./${INTERNAL_BUILD_STATE_DIR_NAME_ACTUAL}/config_from_compile_step.txt"
          echo "$TOOLCHAIN_MD5" > "./${INTERNAL_BUILD_STATE_DIR_NAME_ACTUAL}/toolchain.md5"; echo "$PACKAGE_MD5" > "./${INTERNAL_BUILD_STATE_DIR_NAME_ACTUAL}/package.md5"
          echo "${DOCKER_ENV_FEEDS_CHANGED_FROM_OUTSIDE}" > "./${INTERNAL_BUILD_STATE_DIR_NAME_ACTUAL}/last_feeds_changed_status.txt"
          find feeds -type f -name "Makefile" -exec sha256sum {} \; | sort | sha256sum > "./${INTERNAL_BUILD_STATE_DIR_NAME_ACTUAL}/current_feeds.sha256"
          ccache -s | tee -a "${INTERNAL_DEBUG_LOG}"
          if [ ${final_install_status_docker} -eq 0 ] && [ -n "$(find bin/targets -type f \( -name "*.bin" -o -name "*combined*" -o -name "*sysupgrade*" -o -name "*.img.gz" \) -print -quit)" ]; then
            touch "${DOCKER_ENV_CONTAINER_BUILD_AREA}/.docker_build_status_success"
          else
            touch "${DOCKER_ENV_CONTAINER_BUILD_AREA}/.docker_build_status_failure"
          fi
          cp "${INTERNAL_DEBUG_LOG}" "${DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH}/docker_build_debug_summary.log" || true
          cp "${CCACHE_LOGFILE}" "${DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH}/docker_ccache_detailed.log" || true
          if [ -f "${COMPILE_OUTPUT_LOG_DOCKER}" ]; then cp "${COMPILE_OUTPUT_LOG_DOCKER}" "${DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH}/docker_compile_output.log" || true; fi
          echo "[DOCKER] Build script finished." | tee -a "${INTERNAL_DEBUG_LOG}"
          DOCKER_SCRIPT_EOF

          chmod +x "${RUNNER_SCRIPT_PATH}"
          docker run --rm \
            -v "${{ env.RUNNER_OPENWRT_WORKSPACE }}:${{ env.CONTAINER_BUILD_AREA }}" \
            -v "/workdir/openwrt_s3cache_restore_tmp:/restore_tmp:ro" \
            -v "${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}:${{ env.CONTAINER_REPO_CONFIG_MOUNT }}:ro" \
            -e DOCKER_ENV_REPO_URL="${{ env.REPO_URL }}" \
            -e DOCKER_ENV_REPO_BRANCH="${{ env.REPO_BRANCH }}" \
            -e DOCKER_ENV_FEEDS_CONF_URL="${{ env.FEEDS_CONF_URL }}" \
            -e DOCKER_ENV_CONFIG_FILE_NAME_IN_REPO="${{ env.CONFIG_FILE_IN_REPO }}" \
            -e DOCKER_ENV_DIY_P1_SH_NAME_IN_REPO="${{ env.DIY_P1_SH_IN_REPO }}" \
            -e DOCKER_ENV_DIY_P2_SH_NAME_IN_REPO="${{ env.DIY_P2_SH_IN_REPO }}" \
            -e DOCKER_ENV_BUILD_STATE_DIR_NAME=".github_actions_build_state" \
            -e DOCKER_ENV_CCACHE_DIR_NAME="${{ env.CCACHE_DIR_NAME }}" \
            -e DOCKER_ENV_CONTAINER_DEBUG_LOG_PATH="${{ env.CONTAINER_DEBUG_LOG_FILE_PATH }}" \
            -e DOCKER_ENV_CONTAINER_CCACHE_LOG_PATH="${{ env.CONTAINER_CCACHE_LOGFILE_PATH }}" \
            -e DOCKER_ENV_CONTAINER_BUILD_AREA="${{ env.CONTAINER_BUILD_AREA }}" \
            -e DOCKER_ENV_CONTAINER_REPO_CONFIG_PATH="${{ env.CONTAINER_REPO_CONFIG_MOUNT }}" \
            -e DOCKER_ENV_CLEAN_BUILD_FROM_OUTSIDE="${{ github.event.inputs.clean_build }}" \
            -e DOCKER_ENV_S3_CACHE_RESTORED_FROM_OUTSIDE="${S3_CACHE_RESTORE_ATTEMPTED:-false}" \
            -e DOCKER_ENV_FEEDS_CHANGED_FROM_OUTSIDE="true" \
            -e DOCKER_ENV_BUILD_TZ="${{ env.TZ }}" \
            -e GOFLAGS="-buildvcs=false" \
            ${{ env.DOCKER_IMAGE }} \
            bash -c "cd \"${CONTAINER_BUILD_AREA}\" && \"${CONTAINER_SCRIPT_PATH}\""
          if [ -f "${{ env.RUNNER_OPENWRT_WORKSPACE }}/.docker_build_status_success" ]; then
            echo "Docker build reported success."
            echo "status=success" >> $GITHUB_OUTPUT
            rm -f "${{ env.RUNNER_OPENWRT_WORKSPACE }}/.docker_build_status_success"
          else
            echo "Docker build reported failure or marker not found."
            echo "status=failure" >> $GITHUB_OUTPUT
            rm -f "${{ env.RUNNER_OPENWRT_WORKSPACE }}/.docker_build_status_failure" 2>/dev/null || true
            cp "${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}/docker_build_debug_summary.log" "/tmp/docker_build_debug_summary_runner.log" 2>/dev/null || true
            cp "${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}/docker_ccache_detailed.log" "/tmp/docker_ccache_detailed_runner.log" 2>/dev/null || true
            cp "${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}/docker_compile_output.log" "/tmp/docker_compile_output_runner.log" 2>/dev/null || true
          fi
          rm -f "${RUNNER_SCRIPT_PATH}"

      - name: ä¿®æ­£å·¥ä½œåŒºæ–‡ä»¶æƒé™ (Correct Workspace Permissions)
        if: always()
        run: |
          echo "Adjusting ownership of ${{ env.RUNNER_OPENWRT_WORKSPACE }} to runner user..."
          sudo chown -R $(id -u):$(id -g) "${{ env.RUNNER_OPENWRT_WORKSPACE }}"
          echo "Ownership adjustment complete."

      - name: ä¸Šä¼ è¯Šæ–­æ—¥å¿—åˆ°Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: diagnose_summary
          path: ${{ env.RUNNER_OPENWRT_WORKSPACE }}/bin/targets/__diagnose/diagnose_summary.txt

      - name: Upload Debug Logs (from Runner and potentially Docker)
        if: always()
        uses: actions/upload-artifact@main
        with:
          name: build-debug-logs-${{ github.run_id }}
          path: |
            ${{ env.DEBUG_LOG_ON_RUNNER }}
            ${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}/docker_build_debug_summary.log
            ${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}/docker_ccache_detailed.log
            ${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}/docker_compile_output.log
            ${{ env.RUNNER_OPENWRT_WORKSPACE }}/config_diff.txt
            ${{ env.RUNNER_OPENWRT_WORKSPACE }}/.config
            ${{ env.RUNNER_OPENWRT_WORKSPACE }}/.config.input
            ${{ env.RUNNER_OPENWRT_WORKSPACE }}/logs/
          if-no-files-found: ignore
          retention-days: 7

      - name: æ•´ç†æ–‡ä»¶ (Organize Firmware Files)
        id: organize
        if: steps.compile_in_docker.outputs.status == 'success' && env.UPLOAD_FIRMWARE == 'true' && !cancelled()
        run: |
          echo "å¼€å§‹æ•´ç†å›ºä»¶æ–‡ä»¶ from ${{ env.RUNNER_OPENWRT_WORKSPACE }}/bin ..." | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
          FIRMWARE_COLLECTION_DIR_PATH=""
          OPENWRT_BUILD_ROOT="${{ env.RUNNER_OPENWRT_WORKSPACE }}"
          OPENWRT_BIN_DIR="${OPENWRT_BUILD_ROOT}/bin"
          OPENWRT_TARGETS_DIR="${OPENWRT_BIN_DIR}/targets"
          if [ ! -d "${OPENWRT_TARGETS_DIR}" ]; then
            echo "é”™è¯¯ï¼šç¼–è¯‘ç›®æ ‡ç›®å½• ${OPENWRT_TARGETS_DIR} ä¸å­˜åœ¨ã€‚" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
            FIRMWARE_COLLECTION_DIR_PATH="/tmp/empty_firmware_collection_$(date +%N)"
            mkdir -p "${FIRMWARE_COLLECTION_DIR_PATH}"
            echo "FIRMWARE=${FIRMWARE_COLLECTION_DIR_PATH}" >> $GITHUB_ENV
            echo "status=success" >> $GITHUB_OUTPUT
            echo "FIRMWARE_ZIP=${FIRMWARE_COLLECTION_DIR_PATH}.zip" >> $GITHUB_ENV
            zip -r9 "${FIRMWARE_COLLECTION_DIR_PATH}.zip" "${FIRMWARE_COLLECTION_DIR_PATH}"
            exit 0
          fi
          DEEPEST_TARGET_SUBDIRS=$(find "${OPENWRT_TARGETS_DIR}" -mindepth 2 -maxdepth 2 -type d ! -name "packages" -print)
          if [ -z "${DEEPEST_TARGET_SUBDIRS}" ]; then
              echo "è­¦å‘Šï¼šåœ¨ ${OPENWRT_TARGETS_DIR} ä¸‹æœªæ‰¾åˆ°æ ‡å‡†çš„ç›®æ ‡æ¶æ„å­ç›®å½•ã€‚å°è¯•ç›´æ¥åœ¨ ${OPENWRT_TARGETS_DIR} æœç´¢ã€‚" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
              DEEPEST_TARGET_SUBDIRS="${OPENWRT_TARGETS_DIR}"
          fi
          FINAL_FIRMWARE_OUTPUT_BASE="/tmp/firmware_output_collections"
          mkdir -p "$FINAL_FIRMWARE_OUTPUT_BASE"
          for CURRENT_IMG_SOURCE_DIR in $DEEPEST_TARGET_SUBDIRS; do
              echo "æ£€æŸ¥ç›®å½•: ${CURRENT_IMG_SOURCE_DIR} ä¸­çš„å›ºä»¶æ–‡ä»¶..." | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
              COLLECTED_FIRMWARE_OUTPUT_DIR="${FINAL_FIRMWARE_OUTPUT_BASE}/firmware_collection_$(basename "${CURRENT_IMG_SOURCE_DIR}")_$(date +%N)"
              mkdir -p "${COLLECTED_FIRMWARE_OUTPUT_DIR}"
              FILES_COPIED_COUNT=0
              cd "${CURRENT_IMG_SOURCE_DIR}"
              for pattern in "*combined.img.gz" "*sysupgrade.img.gz" "*combined-efi.img.gz" "*kernel.bin" "*.img" "*.bin"; do
                  find . -maxdepth 1 -type f -name "$pattern" ! -path "./packages/*" -print0 | while IFS= read -r -d $'\0' found_file; do
                      cp -v -f "${found_file}" "${COLLECTED_FIRMWARE_OUTPUT_DIR}/"
                      FILES_COPIED_COUNT=$((FILES_COPIED_COUNT + 1))
                  done
              done
              if [ $FILES_COPIED_COUNT -eq 0 ]; then
                  echo "åœ¨ ${CURRENT_IMG_SOURCE_DIR} ä¸­æœªæ‰¾åˆ°æ ‡å‡†æ¨¡å¼çš„å›ºä»¶ï¼Œå°è¯•å¤åˆ¶å…¶ä»–å¯èƒ½çš„æ–‡ä»¶..." | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
                  find . -maxdepth 1 -type f \
                    ! -name "*.manifest" ! -name "*.txt" ! -name "*.json" ! -name "*.buildinfo" ! -name "sha256sums" \
                    ! -path "./packages/*" \
                    -print0 | while IFS= read -r -d $'\0' found_file; do
                      cp -v -f "${found_file}" "${COLLECTED_FIRMWARE_OUTPUT_DIR}/"
                      FILES_COPIED_COUNT=$((FILES_COPIED_COUNT + 1))
                  done
              fi
              cd "${{ github.workspace }}/${{ env.RUNNER_CHECKOUT_SUBDIR }}"
              if [ $FILES_COPIED_COUNT -gt 0 ]; then
                  echo "æˆåŠŸä» ${CURRENT_IMG_SOURCE_DIR} å¤åˆ¶ $FILES_COPIED_COUNT ä¸ªæ–‡ä»¶åˆ° ${COLLECTED_FIRMWARE_OUTPUT_DIR}" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
                  if [ -f "${OPENWRT_BUILD_ROOT}/.config" ]; then
                    cp -v -f "${OPENWRT_BUILD_ROOT}/.config" "${COLLECTED_FIRMWARE_OUTPUT_DIR}/config.txt"
                  fi
                  ls -lh "${COLLECTED_FIRMWARE_OUTPUT_DIR}" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
                  FIRMWARE_COLLECTION_DIR_PATH="${COLLECTED_FIRMWARE_OUTPUT_DIR}"
                  break
              else
                  echo "è­¦å‘Š: åœ¨ ${CURRENT_IMG_SOURCE_DIR} ä¸­æœªæ‰¾åˆ°å¯ç”¨å›ºä»¶æ–‡ä»¶å¯æ”¶é›†ã€‚" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
                  rm -rf "${COLLECTED_FIRMWARE_OUTPUT_DIR}"
              fi
          done
          if [ -z "${FIRMWARE_COLLECTION_DIR_PATH}" ]; then
              echo "è­¦å‘Šï¼šæœªèƒ½åœ¨ä»»ä½•æ ‡å‡†ç›®æ ‡å­ç›®å½•ä¸­æ”¶é›†åˆ°å›ºä»¶æ–‡ä»¶ã€‚å¯ç”¨ç´§æ€¥å¤‡ç”¨æ”¶é›†é€»è¾‘ã€‚" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
              FIRMWARE_COLLECTION_DIR_PATH="${FINAL_FIRMWARE_OUTPUT_BASE}/firmware_fallback_collection_$(date +%N)"
              mkdir -p "${FIRMWARE_COLLECTION_DIR_PATH}"
              find "${OPENWRT_TARGETS_DIR}" -type f \( -name "*.bin" -o -name "*.img" -o -name "*.img.gz" \) ! -path "*/packages/*" ! -path "*/firmware_collection_*" -exec cp -v -f {} "${FIRMWARE_COLLECTION_DIR_PATH}/" \;
              if [ -f "${OPENWRT_BUILD_ROOT}/.config" ]; then
                  cp -v -f "${OPENWRT_BUILD_ROOT}/.config" "${FIRMWARE_COLLECTION_DIR_PATH}/config.txt";
              else
                  echo "# Fallback .config - actual .config not found" > "${FIRMWARE_COLLECTION_DIR_PATH}/config.txt";
              fi
          fi
          echo "FIRMWARE=${FIRMWARE_COLLECTION_DIR_PATH}" >> $GITHUB_ENV
          echo "status=success" >> $GITHUB_OUTPUT
          if [ -n "${FIRMWARE_COLLECTION_DIR_PATH}" ] && [ -d "${FIRMWARE_COLLECTION_DIR_PATH}" ] && [ "$(ls -A "${FIRMWARE_COLLECTION_DIR_PATH}")" ]; then
              FIRMWARE_PARENT_DIR=$(dirname "${FIRMWARE_COLLECTION_DIR_PATH}")
              FIRMWARE_BASENAME=$(basename "${FIRMWARE_COLLECTION_DIR_PATH}")
              ZIP_FILENAME="${FIRMWARE_BASENAME}.zip"
              echo "åˆ›å»ºå›ºä»¶å‹ç¼©åŒ… ${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME} ä»ç›®å½• ${FIRMWARE_BASENAME}" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
              cd "${FIRMWARE_PARENT_DIR}" && zip -r9 "${ZIP_FILENAME}" "${FIRMWARE_BASENAME}"
              if [ -f "${ZIP_FILENAME}" ]; then
                  echo "FIRMWARE_ZIP=${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME}" >> $GITHUB_ENV
                  ls -lh "${FIRMWARE_PARENT_DIR}/${ZIP_FILENAME}" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
              else
                  echo "é”™è¯¯ï¼šå‹ç¼©åŒ… ${ZIP_FILENAME} æœªèƒ½æˆåŠŸåˆ›å»ºã€‚" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
                  echo "FIRMWARE_ZIP=/tmp/zip_creation_failed_$(date +%N).zip" >> $GITHUB_ENV
              fi
          else
              echo "è­¦å‘Š: æœ€ç»ˆå›ºä»¶æ”¶é›†ç›®å½• (${FIRMWARE_COLLECTION_DIR_PATH}) æœªæœ‰æ•ˆè®¾ç½®ã€ä¸æ˜¯ç›®å½•æˆ–ä¸ºç©ºï¼Œæ— æ³•åˆ›å»º firmware.zipã€‚" | tee -a "${{ env.DEBUG_LOG_ON_RUNNER }}"
              echo "FIRMWARE_ZIP=/tmp/no_firmware_to_zip_$(date +%N).zip" >> $GITHUB_ENV

      - name: ä¸Šä¼ å›ºä»¶ (Artifact)
        uses: actions/upload-artifact@main
        if: steps.organize.outputs.status == 'success' && env.UPLOAD_FIRMWARE == 'true' && !cancelled()
        with:
          name: OpenWrt_firmware${{ env.DEVICE_NAME }}${{ env.FILE_DATE }}
          path: ${{ env.FIRMWARE_ZIP }}
          if-no-files-found: warn

      - name: ç”Ÿæˆå‘å¸ƒæ ‡ç­¾ (Generate Release Tag)
        id: tag
        if: steps.organize.outputs.status == 'success' && env.UPLOAD_RELEASE == 'true' && !cancelled()
        run: |
          RELEASE_TAG_BASE=$(date +"%Y.%m.%d-%H%M")
          DEVICE_TAG_PART=$(echo "${{ env.DEVICE_NAME }}" | sed 's/^_//;s/_$//' | sed 's/[^a-zA-Z0-9._-]/-/g' )
          if [ -n "$DEVICE_TAG_PART" ] && [ "$DEVICE_TAG_PART" != "-" ]; then FINAL_RELEASE_TAG="${RELEASE_TAG_BASE}_${DEVICE_TAG_PART}"; else FINAL_RELEASE_TAG="${RELEASE_TAG_BASE}"; fi
          echo "RELEASE_TAG=${FINAL_RELEASE_TAG}" >> $GITHUB_OUTPUT
          echo "## OpenWrt Firmware Build ($(date +"%Y-%m-%d %H:%M %Z")) ğŸ“¦" > release_body.txt
          echo "" >> release_body.txt
          echo "**Branch:** \`${{ env.REPO_BRANCH }}\`" >> release_body.txt
          echo "**Config:** \`${{ env.CONFIG_FILE_IN_REPO }}\`" >> release_body.txt
          if [ -n "$DEVICE_TAG_PART" ] && [ "$DEVICE_TAG_PART" != "-" ]; then echo "**Device:** \`${{ env.DEVICE_NAME }}\`" >> release_body.txt; fi
          echo "" >> release_body.txt
          echo "### å›ºä»¶ä¸‹è½½ (Firmware Download)" >> release_body.txt
          echo "è¯·åœ¨ä¸‹æ–¹ Assets ä¸­æ‰¾åˆ°å›ºä»¶æ–‡ä»¶ (é€šå¸¸æ˜¯ä¸€ä¸ª .zip å‹ç¼©åŒ…)ã€‚" >> release_body.txt
          echo "Please find firmware files (usually a .zip archive) in the Assets section below." >> release_body.txt
          echo "" >> release_body.txt; echo "---" >> release_body.txt
          echo "âš ï¸ **åˆ·æœºå‰è¯·åŠ¡å¿…å¤‡ä»½é‡è¦æ•°æ®ï¼**" >> release_body.txt
          echo "âš ï¸ **Backup your important data before flashing!**" >> release_body.txt
          echo "" >> release_body.txt
          echo "_Built by GitHub Actions - Workflow: [${{ github.workflow }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})_" >> release_body.txt
          echo "status=success" >> $GITHUB_OUTPUT

      - name: ä¸Šä¼ å›ºä»¶åˆ°Releases (Upload Firmware to Releases)
        uses: softprops/action-gh-release@v2
        if: steps.tag.outputs.status == 'success' && !cancelled()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ steps.tag.outputs.RELEASE_TAG }}
          body_path: release_body.txt
          files: ${{ env.FIRMWARE_ZIP }}
          
      # ======= æ–°å¢ï¼šåˆ·æ–° CloudFront CDN ç¼“å­˜ =======
      - name: åˆ·æ–° CloudFront CDN ç¼“å­˜ (CloudFront Invalidate Cache)
        if: always()
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          CF_DISTRIBUTION_ID: ${{ secrets.CF_DISTRIBUTION_ID }}
          S3_EFFECTIVE_PATH_PREFIX: ${{ env.S3_EFFECTIVE_PATH_PREFIX }}
        run: |
          echo "å¼€å§‹åˆ·æ–° CloudFront CDN ç¼“å­˜: /${S3_EFFECTIVE_PATH_PREFIX}/*"
          aws cloudfront create-invalidation \
            --distribution-id "$CF_DISTRIBUTION_ID" \
            --paths "/${S3_EFFECTIVE_PATH_PREFIX}/*"
          echo "CloudFront CDN ç¼“å­˜åˆ·æ–°è¯·æ±‚å·²æäº¤"          

      - name: åˆ é™¤æ—§çš„Releases (Delete Old Releases)
        uses: dev-drprasad/delete-older-releases@master
        if: env.UPLOAD_RELEASE == 'true' && !cancelled()
        with:
          keep_latest: 3
          delete_tags: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
